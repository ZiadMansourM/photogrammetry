{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as OpenCV\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImage(image, title = None):\n",
    "    if image.ndim == 2:\n",
    "        plt.gray()\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# OpenCV use BGR format for reading images as it's default \n",
    "# to get RGB images we need to change the format \n",
    "def readImageRGB(imagePath):\n",
    "    return OpenCV.cvtColor(OpenCV.imread(imagePath), OpenCV.COLOR_BGR2RGB)\n",
    "\n",
    "def RGBtoGRAY(images):\n",
    "    return [OpenCV.cvtColor(image, OpenCV.COLOR_RGB2GRAY) for image in images]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all images from file into an array: images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImages(folderPath):\n",
    "    files = sorted(os.listdir(folderPath))\n",
    "    return [\n",
    "        readImageRGB(f\"{folderPath}/{file}\")\n",
    "        for file in files\n",
    "        if \".jpg\" in file\n",
    "    ]\n",
    "\n",
    "images = readImages(\"../src/images/snow-man/\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get gray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayImages = RGBtoGRAY(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayImage(images[0])\n",
    "displayImage(grayImages[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "### Get **SIFT** keypoints & descriptors on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT = OpenCV.SIFT_create()\n",
    "\n",
    "def getSiftKeypoints(imageIndex):\n",
    "    keyPoint, descriptor = SIFT.detectAndCompute(grayImages[imageIndex], None)\n",
    "    return keyPoint, descriptor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get **MSER** keypoints & descriptors on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSER = OpenCV.MSER_create()\n",
    "\n",
    "def getMserKeypoints(imageIndex):\n",
    "    keyPoint = MSER.detect(grayImages[imageIndex], None)\n",
    "    descriptor = MSER.compute(grayImages[imageIndex], keyPoint)\n",
    "    return keyPoint, descriptor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the keypoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawKeypoints(images, grayImages, keyPoints, method = \"SIFT\"):\n",
    "    for i in range(len(images)):\n",
    "        img = OpenCV.drawKeypoints(grayImages[i], keyPoints[i], images[i], flags = OpenCV.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "        OpenCV.imwrite(f\"keyPoints/{method}/{str(i)}.jpg\", img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get keypoints & descriptors for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllImagesKeyPoints(images, method = \"SIFT\"):\n",
    "    keyPoints = []\n",
    "    descriptors = []\n",
    "    for i in range(len(images)):\n",
    "        if method == \"SIFT\":\n",
    "            keyPoint, descriptor = getSiftKeypoints(i)\n",
    "        elif method == \"MSER\":\n",
    "            keyPoint, descriptor = getMserKeypoints(i)\n",
    "        keyPoints.append(np.array(keyPoint))\n",
    "        descriptors.append(np.array(descriptor))\n",
    "    return keyPoints, descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "# import cv2\n",
    "\n",
    "# def getSiftKeypoints(image):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     sift = cv2.SIFT_create()\n",
    "#     keyPoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "#     return keyPoints, descriptors\n",
    "\n",
    "# def process_image(i, images):\n",
    "#     return getSiftKeypoints(images[i])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     images = [...]  # list of images\n",
    "#     num_images = len(images)\n",
    "#     pool = mp.Pool(mp.cpu_count())\n",
    "#     results = [pool.apply_async(process_image, args=(i, images)) for i in range(num_images)]\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#     keyPoints = []\n",
    "#     descriptors = []\n",
    "#     for res in results:\n",
    "#         k, d = res.get()\n",
    "#         keyPoints.append(k)\n",
    "#         descriptors.append(d)\n",
    "#     print(keyPoints, descriptors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT keypoints & descriptors on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkeyPoints, Sdescriptors = getAllImagesKeyPoints(images, \"SIFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SkeyPoints[0][0].pt, SkeyPoints[0][0].size, SkeyPoints[0][0].angle, SkeyPoints[0][0].response, SkeyPoints[0][0].octave, SkeyPoints[0][0].class_id)\n",
    "# [\n",
    "#         [\n",
    "#             print(kp.pt, kp.size, kp.angle, kp.response, kp.octave, kp.class_id)\n",
    "#             for kp in kp_list\n",
    "#         ] for kp_list in SkeyPoints \n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../src/bak/snow-man/sift-features.pkl\", 'rb') as f:\n",
    "    keypoints_tuple, descriptors = pickle.load(f)\n",
    "print(keypoints_tuple[0][0])\n",
    "print(keypoints_tuple[0][1])\n",
    "# cv2.KeyPoint(x=0.0, y=0.0, _size=0.0, _angle=-1.0, _response=0.0, _octave=0, _class_id=-1)\n",
    "obj_list = []\n",
    "for i, kp_array in enumerate(keypoints_tuple):\n",
    "    for j, kp in enumerate(kp_array):\n",
    "        print(i, j, kp)\n",
    "        obj = OpenCV.KeyPoint(x=kp[0][0], y=kp[0][1], size=kp[1], angle=kp[2], response=kp[3], octave=kp[4], class_id=kp[5])\n",
    "        obj_list.append(obj)\n",
    "        print(\"success\")\n",
    "# [\n",
    "#         [\n",
    "#             OpenCV.KeyPoint(x=kp[0][0], y=kp[0][1], _size=kp[1], _angle=kp[2], _response=kp[3], _octave=kp[4], _class_id=kp[5]) \n",
    "#             for kp in kp_array\n",
    "#         ] for kp_array in keypoints_tuple\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkeyPoints, Sdescriptors = getAllImagesKeyPointsParallel(images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⛔️ MSER keypoints & descriptors on all images\n",
    "still have error in this part (most likely due to the gpu type used )\n",
    "try to run it on a different machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MkeyPoints, Mdescriptors = getAllImagesKeyPoints(images, \"MSER\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw keypoints for all images (SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not os.path.exists(\"keyPoints\")):\n",
    "    os.mkdir(\"keyPoints\")\n",
    "if (not os.path.exists(\"keyPoints/SIFT\")):\n",
    "    os.mkdir(\"keyPoints/SIFT\")\n",
    "\n",
    "drawKeypoints(images, grayImages, SkeyPoints, \"SIFT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⛔️ Draw keypoints for all images (MSER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (not os.path.exists(\"keyPoints\")):\n",
    "#     os.mkdir(\"keyPoints\")\n",
    "# if (not os.path.exists(\"keyPoints/MSER\")):\n",
    "#     os.mkdir(\"keyPoints/MSER\")\n",
    "\n",
    "# drawKeypoints(images, grayImages, MkeyPoints, \"MSER\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDescriptors = []\n",
    "for descriptors in Sdescriptors:\n",
    "    allDescriptors.extend(iter(descriptors))\n",
    "allDescriptors = np.stack(allDescriptors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clusters from descriptors using **Kmeans** \n",
    "#### don't run this, load the file only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.vq import kmeans\n",
    "\n",
    "# clusters = 400\n",
    "# iter = 2\n",
    "# centroids, variance = kmeans(allDescriptors, clusters, iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the centroids for later use intstead of training multiple times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump((clusters,centroids), \"centroids.pkl\", compress = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the file that stores the centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "clusters, centroids = joblib.load(\"centroids.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the visualWords \n",
    "⛔️ Make sure to run **getSiftKeypoints** first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq\n",
    "\n",
    "visualWords = []\n",
    "for descriptors in Sdescriptors:\n",
    "    words, _ = vq(descriptors, centroids)\n",
    "    visualWords.append(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the frequency of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_vectors = []\n",
    "for img_words in visualWords:\n",
    "    histogram = np.zeros(clusters)\n",
    "    for word in img_words:\n",
    "        histogram[word] += 1\n",
    "    frequency_vectors.append(histogram)\n",
    "\n",
    "frequency_vectors = np.stack(frequency_vectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the frequency of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(clusters)), frequency_vectors[100])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TFIDF**: get the visual words that does that most effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(images)\n",
    "\n",
    "df = np.sum(frequency_vectors > 0, axis = 0)\n",
    "idf = np.log(n/df)\n",
    "tfidf = frequency_vectors * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(clusters)), tfidf[100])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring and searching for image matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "b = tfidf\n",
    "def search_display(i: int, top_clusters: int = 5):\n",
    "\n",
    "    print(\"Search image:\")\n",
    "    # show the search image\n",
    "    displayImage(images[i])\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "    a = tfidf[i]\n",
    "    cosine_similarity = np.dot(a, b.T)/(norm(a) * norm(b, axis=1))\n",
    "    idx = np.argsort(-cosine_similarity)[:top_clusters]\n",
    "    # display the results\n",
    "\n",
    "    for i in idx:\n",
    "        print(f\"{str(i)}: {str(cosine_similarity[i])}\")\n",
    "        displayImage(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tfidf\n",
    "# def search(i: int, top_clusters: int = 5):\n",
    "#     a = tfidf[i]\n",
    "#     cosine_similarity = np.dot(a, b.T)/(norm(a) * norm(b, axis=1))\n",
    "#     idx = np.argsort(-cosine_similarity)[:top_clusters]\n",
    "#     return idx\n",
    "def search(i: int, top_clusters: int = 5):\n",
    "    a = tfidf[i]\n",
    "    b_subset = b[:tfidf.shape[0]]  # ensure b has the same number of rows as tfidf\n",
    "    cosine_similarity = np.dot(a, b_subset.T)/(norm(a) * norm(b_subset, axis=1))\n",
    "    idx = np.argsort(-cosine_similarity)[:top_clusters]\n",
    "    # group index and similarity together in a tuple\n",
    "    return list(zip(idx, cosine_similarity[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_display(8,10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best 30 matches for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchesIDs = [search(i, 10) for i in range(len(images))]\n",
    "print(*matchesIDs[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matching\n",
    "### Get the matching features between 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMatching(imgID1, imgID2, Sdescriptors):\n",
    "    matcher = OpenCV.BFMatcher()\n",
    "    return matcher.match(Sdescriptors[imgID1], Sdescriptors[imgID2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = featureMatching(0, 1, Sdescriptors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMatches(matches):\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        return matches[:int(len(matches)*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import time\n",
    "# # Initialize loging to file tune.log in current directory\n",
    "# logging.basicConfig(filename='tune.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# logging.info('Hello, world!')\n",
    "# def dataFeatureMatching(matchesIDs, Sdescriptors):\n",
    "#     num_images = len(Sdescriptors)\n",
    "#     checked = np.zeros((num_images, num_images), dtype=int)\n",
    "#     matches_list = []\n",
    "#     for imageID in range(len(matchesIDs)):\n",
    "#         logging.info(f\"---------- START Matches for: {str(imageID)}\")\n",
    "#         for i, (matchedID, probability) in enumerate(matchesIDs[imageID]):\n",
    "#             if ((checked[imageID][matchedID] == 0 or checked[matchedID][imageID] == 0) and imageID != matchedID and probability > 0.93):\n",
    "#                 start_time = time.time()\n",
    "#                 matches_list.append([imageID, matchedID, featureMatching(imageID, matchedID, Sdescriptors)])\n",
    "#                 checked[imageID][matchedID], checked[matchedID][imageID] = 1, 1\n",
    "#                 logging.info(f\"done [{i}/{len(matchesIDs[imageID])}] in {(time.time() - start_time):.4f}: {str(imageID)} - {str(matchedID)}\")\n",
    "#         # Flush the log file force write to disk\n",
    "#         logging.shutdown()\n",
    "#         # print(f\"---------- DONE Matches for: {str(imageID)}\")\n",
    "#     return matches_list\n",
    "\n",
    "# featuresMatches = dataFeatureMatching(matchesIDs, Sdescriptors)\n",
    "\n",
    "import logging\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "# Initialize loging to file tune.log in current directory\n",
    "logging.basicConfig(filename='tune.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info('Hello, world!')\n",
    "\n",
    "def dataFeatureMatching(matchesIDs, Sdescriptors):\n",
    "    num_images = len(Sdescriptors)\n",
    "    checked = np.zeros((num_images, num_images), dtype=int)\n",
    "    matches_list = []\n",
    "\n",
    "    # Define the worker function for processing a single image\n",
    "    def process_image(imageID):\n",
    "        logging.info(f\"---------- START Matches for: {str(imageID)}\")\n",
    "        matches = []\n",
    "        for i, (matchedID, probability) in enumerate(matchesIDs[imageID]):\n",
    "            if ((checked[imageID][matchedID] == 0 or checked[matchedID][imageID] == 0) and imageID != matchedID and probability > 0.93):\n",
    "                start_time = time.time()\n",
    "                matches.append([imageID, matchedID, featureMatching(imageID, matchedID, Sdescriptors)])\n",
    "                checked[imageID][matchedID], checked[matchedID][imageID] = 1, 1\n",
    "                logging.info(f\"done [{i}/{len(matchesIDs[imageID])}] in {(time.time() - start_time):.4f}: {str(imageID)} - {str(matchedID)}\")\n",
    "        return matches\n",
    "\n",
    "    # Use a thread pool executor to process the images in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_images) as executor:\n",
    "        futures = []\n",
    "        for imageID in range(num_images):\n",
    "            future = executor.submit(process_image, imageID)\n",
    "            futures.append(future)\n",
    "\n",
    "        # Combine the results from all the futures\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            matches_list.extend(future.result())\n",
    "\n",
    "    # Flush the log file force write to disk\n",
    "    logging.shutdown()\n",
    "    return matches_list\n",
    "\n",
    "featuresMatches = dataFeatureMatching(matchesIDs, Sdescriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save featuresMatches to file\n",
    "\n",
    "def convert_matches_to_dicts(matches):\n",
    "    match_dicts = []\n",
    "    for match in matches:\n",
    "        match_dict = {'queryIdx': match.queryIdx, 'trainIdx': match.trainIdx, 'distance': match.distance}\n",
    "        match_dicts.append(match_dict)\n",
    "    return match_dicts\n",
    "\n",
    "# Convert cv2.DMatch objects to dictionaries before pickling\n",
    "matches_dicts = [\n",
    "    [match[0], match[1], convert_matches_to_dicts(match[2])]\n",
    "    for match in featuresMatches\n",
    "]\n",
    "# Serialize the matches_dicts list using pickle\n",
    "with open('featuresMatches.pkl', 'wb') as f:\n",
    "    pickle.dump(matches_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matches_dicts list from the file\n",
    "with open('featuresMatches_12_3_Mohamed.pkl', 'rb') as f:\n",
    "    loaded_matches_dicts = pickle.load(f)\n",
    "\n",
    "# Convert dictionaries back to cv2.DMatch objects after unpickling\n",
    "loaded_featuresMatches = []\n",
    "for match_dict in loaded_matches_dicts:\n",
    "    matches = [OpenCV.DMatch(match['queryIdx'], match['trainIdx'], match['distance']) for match in match_dict[2]]\n",
    "    loaded_featuresMatches.append([match_dict[0], match_dict[1], matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(loaded_featuresMatches))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b23c45be9a076254976d995e266fc117c16c2139cae9117842e15f7381998c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
