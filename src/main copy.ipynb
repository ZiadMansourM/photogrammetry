{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import uuid\n",
    "from typing import Final, Optional\n",
    "\n",
    "import cv2 as OpenCV\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from scipy.spatial import Delaunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def print_size(obj):\n",
    "    \"\"\"\n",
    "    Prints the memory usage of a Python object.\n",
    "\n",
    "    Parameters:\n",
    "    obj: Any Python object\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Get the memory usage of the object in bytes\n",
    "    memory_usage = sys.getsizeof(obj)\n",
    "\n",
    "    # Convert memory usage to a more readable format\n",
    "    if memory_usage < 1024:\n",
    "        memory_usage_str = f\"{memory_usage} bytes\"\n",
    "    elif memory_usage < 1024 ** 2:\n",
    "        memory_usage_str = f\"{memory_usage / 1024} KB\"\n",
    "    elif memory_usage < 1024 ** 3:\n",
    "        memory_usage_str = f\"{memory_usage / (1024 ** 2)} MB\"\n",
    "    else:\n",
    "        memory_usage_str = f\"{memory_usage / (1024 ** 3)} GB\"\n",
    "\n",
    "    # Print the memory usage\n",
    "    print(f\"Memory usage of the object: {memory_usage_str}\")\n",
    "\n",
    "def mem_usage():\n",
    "    import psutil\n",
    "\n",
    "    # Get the current process ID\n",
    "    pid = psutil.Process()\n",
    "\n",
    "    # Get the memory usage in bytes\n",
    "    memory_usage = pid.memory_info().rss\n",
    "\n",
    "    # Convert memory usage to GB\n",
    "    memory_usage_gb = memory_usage / (1024 ** 3)\n",
    "\n",
    "    # Print the memory usage in GB\n",
    "    print(f\"Memory usage: {memory_usage_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "class IntrinsicParametersNotFoundError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    def __init__(self, img_id, rgb_image, gray_image, keypoints, descriptors, path):\n",
    "        self.img_id: int = img_id\n",
    "        self.unique_id: uuid = uuid.uuid4()\n",
    "        self.rgb_image: Image = rgb_image\n",
    "        self.gray_image: Image = gray_image\n",
    "        self.keypoints: list[OpenCV.KeyPoint] = keypoints\n",
    "        self.descriptors: np.ndarray = descriptors\n",
    "        self.path: str = path\n",
    "        self.similar_images: list[tuple[Image, float]] = []\n",
    "\n",
    "    @property\n",
    "    def length(self):\n",
    "        return f\"{len(self.keypoints)}\" if len(self.keypoints) == len(self.descriptors) else f\"{len(self.keypoints)}, {len(self.descriptors)}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Image({self.img_id})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.unique_id == other.unique_id\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.img_id)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        state['keypoints'] = [tuple(k.pt) + (k.size, k.angle, k.response, k.octave, k.class_id) for k in self.keypoints]\n",
    "        return state\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        state['keypoints'] = [OpenCV.KeyPoint(x, y, size, angle, response, octave, class_id) for x, y, size, angle, response, octave, class_id in state['keypoints']]\n",
    "        self.__dict__ = state\n",
    "\n",
    "class FeatureMatches:\n",
    "    def __init__(self, image_one: Image, image_two: Image, matches: list[OpenCV.DMatch]):\n",
    "        self.image_one: Image = image_one\n",
    "        self.image_two: Image = image_two\n",
    "        self.matches: list[OpenCV.DMatch] = matches\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FeatureMatches({self.image_one}, {self.image_two} ---> {len(self.matches)})\"\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        state['matches'] = [\n",
    "            {'queryIdx': m.queryIdx, 'trainIdx': m.trainIdx, 'distance': m.distance} for m in self.matches\n",
    "        ]\n",
    "        return state\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        state['matches'] = [\n",
    "            OpenCV.DMatch(match['queryIdx'], match['trainIdx'], match['distance']) for match in state['matches']\n",
    "        ]\n",
    "        self.__dict__ = state\n",
    "    \n",
    "class Images:\n",
    "    def __init__(self, images: list[Image], image_set_name: str):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.images: list[Image] = images\n",
    "        self.image_set_name: str = image_set_name\n",
    "        self.feature_matches: list[FeatureMatches] = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step One: Read and Load Images\n",
    "Inputs: \n",
    "- folder_path: str\n",
    "\n",
    "Outputs:\n",
    "- images: Images\n",
    "\n",
    "Main Functions:\n",
    "1. prepare_images: read and load images from a folder into an Images object\n",
    "\n",
    "Utils Functions:\n",
    "1. dump_images: dump images to a pickle file\n",
    "2. load_images: load images from a pickle file\n",
    "\"\"\"\n",
    "\n",
    "def prepare_images(folder_path: str) -> Images:\n",
    "    \"\"\" Read and load images \"\"\"\n",
    "    images: Images = Images([], folder_path.split(\"/\")[-1])\n",
    "    files: list[str] = filter(lambda file: \".jpg\" in file, os.listdir(folder_path))\n",
    "    for i, file in enumerate(files):\n",
    "        image_path = f\"{folder_path}/{file}\"\n",
    "        rgb_image = OpenCV.cvtColor(OpenCV.imread(image_path), OpenCV.COLOR_BGR2RGB)\n",
    "        gray_image = OpenCV.cvtColor(rgb_image, OpenCV.COLOR_RGB2GRAY)\n",
    "        images.images.append(Image(i, rgb_image, gray_image, [], [], image_path))\n",
    "    return images\n",
    "\n",
    "def dump_images_bak(images_file_path: str, images: Images) -> None:\n",
    "    \"\"\" Dump images to a file \"\"\"\n",
    "    with open(images_file_path, \"wb\") as file:\n",
    "        pickle.dump(images, file)\n",
    "\n",
    "def load_images_bak(images_file_path: str) -> Images:\n",
    "    \"\"\" Load images from a file \"\"\"\n",
    "    with open(images_file_path, \"rb\") as file:\n",
    "        images = pickle.load(file)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step Two: Feature Extraction\n",
    "Inputs:\n",
    "- images: Images\n",
    "- SIFT: OpenCV.SIFT\n",
    "\n",
    "Outputs:\n",
    "- image: Image\n",
    "--> image.keypoints: list[OpenCV.KeyPoint]\n",
    "--> image.descriptors: np.ndarray\n",
    "\n",
    "Main Functions:\n",
    "1. compute_keypoints_descriptors\n",
    "\"\"\"\n",
    "\n",
    "def compute_keypoints_descriptors(images: list[Image], SIFT: OpenCV.SIFT) -> None:\n",
    "    \"\"\"Compute keypoints and descriptors for each image in the list of images using SIFT algorithm.\n",
    "    Modifies each image in the list of images by adding its keypoints and descriptors as attributes.\n",
    "    \n",
    "    Args:\n",
    "    - images: List of images to compute keypoints and descriptors for.\n",
    "    - SIFT: OpenCV SIFT object used to detect and compute keypoints and descriptors.\n",
    "\n",
    "    Returns:\n",
    "    - None.\n",
    "    \"\"\"\n",
    "    for img in images.images:\n",
    "        keypoints: list[OpenCV.KeyPoint]\n",
    "        descriptors: np.ndarray\n",
    "        keypoints, descriptors = SIFT.detectAndCompute(img.gray_image, None)\n",
    "        img.keypoints = keypoints\n",
    "        img.descriptors = descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step Three: Image Matching\n",
    "Inputs:\n",
    "- descriptors: list[np.ndarray]\n",
    "\n",
    "Outputs:\n",
    "- centroids: np.ndarray\n",
    "- variance: np.ndarray\n",
    "- CLUSTER_COUNT: int\n",
    "- matches_ids: list[list[tuple[int, float]]]\n",
    "\n",
    "Main Functions:\n",
    "1. get_matches\n",
    "\n",
    "Utils Functions:\n",
    "1. get_matches_ids\n",
    "\n",
    "Sub Utils Functions:\n",
    "1. get_visual_words\n",
    "2. get_frequency_vectors\n",
    "3. get_tf_idf\n",
    "4. search_matches\n",
    "\"\"\"\n",
    "\n",
    "def get_matches(images: Images) -> None:\n",
    "    \"\"\" Match images using k-means clustering.\n",
    "    Args:\n",
    "        images: Obj from Images class.\n",
    "    \"\"\"\n",
    "    all_descriptors = np.concatenate([image.descriptors for image in images.images])\n",
    "    CLUSTER_COUNT: Final = 400\n",
    "    ITER: Final = 2\n",
    "    centroids, _ = kmeans(all_descriptors, CLUSTER_COUNT, ITER)\n",
    "    matches_ids: list[list[tuple[int, float]]] =  get_matches_ids([image.descriptors for image in images.images], centroids, images.images)\n",
    "    for i, image in enumerate(images.images):\n",
    "        inner_list: list[Image, float] = [\n",
    "            (images.images[match[0]], match[1]) for match in matches_ids[i]\n",
    "        ]\n",
    "        image.similar_images = inner_list\n",
    "\n",
    "\n",
    "def get_visual_words(descriptors: list[np.ndarray], centroids: np.ndarray) -> list[np.ndarray]:\n",
    "    \"\"\" Get the visual words of a list of descriptors.\n",
    "    Args:\n",
    "        descriptors: A list of numpy arrays containing image descriptors.\n",
    "        centroids: A numpy array containing cluster centroids.\n",
    "    Returns:\n",
    "        A list of numpy arrays representing the visual words of each image.\n",
    "    \"\"\"\n",
    "    visual_words = []\n",
    "    for descriptor in descriptors:\n",
    "        words, _ = vq(descriptor, centroids)\n",
    "        visual_words.append(words)\n",
    "    return visual_words\n",
    "\n",
    "\n",
    "def get_frequency_vectors(visual_words: list[np.ndarray], CLUSTER_COUNT: int) -> np.ndarray:\n",
    "    \"\"\" Get the frequency vectors for a list of visual words.\n",
    "    Args:\n",
    "        visual_words: A list of numpy arrays representing the visual words of each image.\n",
    "        CLUSTER_COUNT: The number of clusters used to generate the visual words.\n",
    "    Returns:\n",
    "        A numpy array containing the frequency vectors for each image.\n",
    "    \"\"\"\n",
    "    frequency_vectors = []\n",
    "    for img_words in visual_words:\n",
    "        histogram = np.zeros(CLUSTER_COUNT)\n",
    "        for word in img_words:\n",
    "            histogram[word] += 1\n",
    "        frequency_vectors.append(histogram)\n",
    "    return np.stack(frequency_vectors)\n",
    "\n",
    "\n",
    "def get_tf_idf(frequency_vectors, IMAGES_COUNT) -> np.ndarray:\n",
    "    \"\"\" Get the Term Frequency-Inverse Document Frequency (TF-IDF) matrix for a list of frequency vectors.\n",
    "    Args:\n",
    "        frequency_vectors: A numpy array containing the frequency vectors for each image.\n",
    "        IMAGES_COUNT: The total number of images in the dataset.\n",
    "    Returns:\n",
    "        A numpy array containing the TF-IDF matrix for the input frequency vectors.\n",
    "    \"\"\"\n",
    "    df = np.sum(frequency_vectors > 0, axis = 0)\n",
    "    idf = np.log(IMAGES_COUNT/df)\n",
    "    return frequency_vectors * idf\n",
    "\n",
    "\n",
    "def search_matches(i, top_clusters, tf_idf) -> list[tuple[int, float]]:\n",
    "    \"\"\" Search for the top_clusters most similar images to the i-th image\n",
    "    Args:\n",
    "        i: the index of the image to search for similar images\n",
    "        top_clusters: the number of similar images to return\n",
    "        tf_idf: Term Frequency-Inverse Document Frequency\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple contains the index of a similar image and the cosine similarity \n",
    "        between the i-th image and the similar image. The list is sorted by the cosine similarity in \n",
    "        descending order.\n",
    "    \"\"\"\n",
    "    b = tf_idf\n",
    "    a = tf_idf[i]\n",
    "    b_subset = b[:tf_idf.shape[0]]\n",
    "    cosine_similarity = np.dot(a, b_subset.T)/(norm(a) * norm(b_subset, axis=1))\n",
    "    idx = np.argsort(-cosine_similarity)[:top_clusters]\n",
    "    return list(zip(idx, cosine_similarity[idx]))\n",
    "\n",
    "\n",
    "def get_matches_ids(descriptors, centroids, images_list) -> list[list[tuple[int, float]]]:\n",
    "    \"\"\"Returns: a list of lists, where each list contains the top 10 most similar images to the i-th image.\"\"\"\n",
    "    visual_words = get_visual_words(descriptors, centroids)\n",
    "    frequency_vectors = get_frequency_vectors(visual_words, centroids.shape[0])\n",
    "    \"\"\" tf_idf: Term Frequency-Inverse Document Frequency \"\"\"\n",
    "    tf_idf = get_tf_idf(frequency_vectors, len(images_list))\n",
    "    return [\n",
    "        search_matches(i, 10, tf_idf)\n",
    "        for i in range(len(images_list))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step Four: Feature Matching\n",
    "Inputs:\n",
    "- images: Images\n",
    "\n",
    "Outputs:\n",
    "- None\n",
    "\n",
    "Main Functions:\n",
    "1. data_feature_matching\n",
    "\n",
    "Utils Functions:\n",
    "1. feature_matching\n",
    "\"\"\"\n",
    "\n",
    "def feature_matching(\n",
    "        img_one_descriptors: np.ndarray, \n",
    "        img_two_descriptors: np.ndarray\n",
    "    ) -> list[OpenCV.DMatch]:\n",
    "    \"\"\" Match features between two images using Brute Force Matcher\n",
    "    Args:\n",
    "        img_id_one: the index of the first image\n",
    "        img_id_two: the index of the second image\n",
    "        descriptors: a list of descriptors of the images\n",
    "    Returns:\n",
    "        A list of OpenCV.DMatch objects.\n",
    "    \"\"\"\n",
    "    matcher = OpenCV.BFMatcher()\n",
    "    return matcher.match(img_one_descriptors, img_two_descriptors)\n",
    "\n",
    "def data_feature_matching(images: Images) -> None:\n",
    "    \"\"\" Match features between images using Brute Force Matcher\n",
    "    Args:\n",
    "        matchesIDs: a list of lists of tuples, where each tuple contains the index of a similar image and the cosine similarity \n",
    "            between the i-th image and the similar image. The list is sorted by the cosine similarity in \n",
    "            descending order.\n",
    "        descriptors: a list of descriptors of the images\n",
    "    Returns:\n",
    "        A list of lists, where each list contains \n",
    "        the index of the first image, the index of the second image, \n",
    "        and a list of OpenCV.DMatch objects.\n",
    "    \"\"\"\n",
    "    num_images: int = len(images.images)\n",
    "    checked = np.zeros((num_images, num_images), dtype=int)\n",
    "    for image in images.images:\n",
    "        for matched_image, probability in image.similar_images:\n",
    "            if ((checked[image.img_id][matched_image.img_id] == 0 or checked[matched_image.img_id][image.img_id] == 0) and image.img_id != matched_image.img_id and probability > 0.93):\n",
    "                images.feature_matches.append(FeatureMatches(image, matched_image, feature_matching(image.descriptors, matched_image.descriptors)))\n",
    "                checked[image.img_id][matched_image.img_id], checked[matched_image.img_id][image.img_id] = 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step Five: Camera Calibration\\nInputs:\\n- None.\\n\\nOutputs:\\n- k_matrix: np.ndarray\\n\\nToDo:\\n1- generate K_matrix.pickle for each camera using Chess board pattern.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Step Five: Camera Calibration\n",
    "Inputs:\n",
    "- None.\n",
    "\n",
    "Outputs:\n",
    "- k_matrix: np.ndarray\n",
    "\n",
    "ToDo:\n",
    "1- generate K_matrix.pickle for each camera using Chess board pattern.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step Six: Triangulation (3D Reconstruction)\n",
    "Inputs:\n",
    "- feature_matches_list: list[list[int, int, list[OpenCV.DMatch]]]\n",
    "    -> A list of lists, where each list contains \n",
    "        the index of the first image, the index of the second image, \n",
    "        and a list of OpenCV.DMatch objects.\n",
    "- K_matrix: np.ndarray\n",
    "    -> The camera matrix of the camera used to take the images.\n",
    "\n",
    "Outputs:\n",
    "- point_cloud: list[np.ndarray]; each element is a 3D point.\n",
    "\n",
    "Main Functions:\n",
    "1. generate_point_cloud\n",
    "\n",
    "Utils Functions:\n",
    "1. triangulatePoints\n",
    "\"\"\"\n",
    "\n",
    "def triangulatePoints(P1, P2, pts1, pts2):\n",
    "    \"\"\"\n",
    "    Triangulates the given matching points from two images using the given camera matrices.\n",
    "\n",
    "    Parameters:\n",
    "    P1 (numpy.ndarray): 3x4 camera matrix of the first image.\n",
    "    P2 (numpy.ndarray): 3x4 camera matrix of the second image.\n",
    "    pts1 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the first image.\n",
    "    pts2 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the second image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the triangulated 3D points.\n",
    "    \"\"\"\n",
    "    pts4D = OpenCV.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "    pts4D /= pts4D[3]\n",
    "    return pts4D[:3].T\n",
    "\n",
    "\n",
    "def generate_point_cloud(images: Images, K_matrix):\n",
    "    \"\"\"\n",
    "    Generates a cloud of 3D points using triangulation from feature matches and camera calibration matrix.\n",
    "\n",
    "    Parameters:\n",
    "    feature_matches_list (list): List of feature matches between images.\n",
    "    K_matrix (numpy.ndarray): 3x3 camera calibration matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the cloud of 3D points.\n",
    "    \"\"\"\n",
    "    point_cloud = []\n",
    "    feature_matches_list = images.feature_matches\n",
    "    for match in feature_matches_list:\n",
    "        img_one = match.image_one\n",
    "        img_two = match.image_two\n",
    "        matches = match.matches\n",
    "        pts1 = np.float32([img_one.keypoints[m.queryIdx].pt for m in matches])\n",
    "        pts2 = np.float32([img_two.keypoints[m.trainIdx].pt for m in matches])\n",
    "        E, _ = OpenCV.findEssentialMat(pts1, pts2, K_matrix)\n",
    "        R1, R2, t = OpenCV.decomposeEssentialMat(E)\n",
    "        P1 = np.hstack((np.eye(3), np.zeros((3,1))))\n",
    "        P2 = np.hstack((R1, t))\n",
    "        pts_3d = triangulatePoints(P1, P2, pts1, pts2)\n",
    "        point_cloud.append(pts_3d)\n",
    "    return np.concatenate(point_cloud, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome ScanMate...\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome ScanMate...\")\n",
    "# image_set_name = \"rubik-cube\"\n",
    "image_set_name = \"snow-man\"\n",
    "images: Optional[Images] = None\n",
    "# Reload the last state\n",
    "last_state: str\n",
    "if os.path.isfile(f\"bak/{image_set_name}/point-cloud.pkl\"):\n",
    "    last_state = \"Point Cloud Step\"\n",
    "elif os.path.isfile(f\"bak/{image_set_name}/feature-matching-output.pkl\"):\n",
    "    last_state = \"Feature Matching Step\"\n",
    "elif os.path.isfile(f\"bak/{image_set_name}/images-matched.pkl\"):\n",
    "    last_state = \"Images Matching Step\"\n",
    "elif os.path.isfile(f\"bak/{image_set_name}/sift-features.pkl\"):\n",
    "    last_state = \"SIFT Features Step\"\n",
    "else:\n",
    "    last_state = \"Images Loading Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point Cloud Step\n"
     ]
    }
   ],
   "source": [
    "print(last_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_state = \"Images Loading Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File [bak/snow-man/sift-images.pkl] exists\n",
      "Loading images from pickle file...\n",
      "Images loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare Images\n",
    "if last_state == \"Images Loading Step\":\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/images.pkl\"):\n",
    "        print(f\"File [bak/{image_set_name}/sift-images.pkl] exists\")\n",
    "        print(\"Loading images from pickle file...\")\n",
    "        images: Images = load_images_bak(f\"bak/{image_set_name}/images.pkl\")\n",
    "    else:\n",
    "        print(f\"File [bak/{image_set_name}/images.pkl] does not exist\")\n",
    "        print(\"Loading images from images directory...\")\n",
    "        images: Images = prepare_images(f\"images/{image_set_name}\")\n",
    "        print(\"Saving images to pickle file...\")\n",
    "        dump_images_bak(f\"bak/{image_set_name}/images.pkl\", images)\n",
    "    print(\"Images loaded successfully\")\n",
    "    last_state = \"SIFT Features Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(len(image.descriptors) for image in images.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File [bak/{image_set_name}/sift-features.pkl] DO NOT exists\n",
      "Extracting SIFT features...\n",
      "File bak/snow-man/images.pkl removed successfully.\n",
      "Feature Extraction: SIFT DONE...\n"
     ]
    }
   ],
   "source": [
    "# 2. Feature Extraction: SIFT\n",
    "if last_state == \"SIFT Features Step\":\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/sift-features.pkl\"):\n",
    "        print(f\"File [bak/{image_set_name}/sift-features.pkl] exists\")\n",
    "        if images: \n",
    "            del images\n",
    "        images: Images = load_images_bak(f\"bak/{image_set_name}/sift-features.pkl\")\n",
    "    else:\n",
    "        print(\"File [bak/{image_set_name}/sift-features.pkl] DO NOT exists\")\n",
    "        print(\"Extracting SIFT features...\")\n",
    "        sift = OpenCV.SIFT_create()\n",
    "        compute_keypoints_descriptors(images, sift)\n",
    "        dump_images_bak(f\"bak/{image_set_name}/sift-features.pkl\", images)\n",
    "        # remove bak/{image_set_name}/images.pkl\n",
    "        if os.path.exists(f\"bak/{image_set_name}/images.pkl\"):\n",
    "            os.remove(f\"bak/{image_set_name}/images.pkl\")\n",
    "            print(f\"File bak/{image_set_name}/images.pkl removed successfully.\")\n",
    "        else:\n",
    "            print(f\"File bak/{image_set_name}/images.pkl does not exist.\")\n",
    "    print(\"Feature Extraction: SIFT DONE...\")\n",
    "    last_state = \"Images Matching Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({30209: 1, 23071: 1, 12823: 1, 7230: 1, 22413: 1, 3357: 1, 8848: 1, 3925: 1, 42699: 1, 24060: 1, 12652: 1, 4665: 1, 1066: 1, 4034: 1, 1411: 1, 8548: 1, 6014: 1, 1464: 1, 9389: 1, 20041: 1, 19830: 1, 6859: 1, 3894: 1, 12667: 1, 6466: 1, 3149: 1, 5084: 1, 52593: 1, 102355: 1, 32483: 1, 23916: 1, 5067: 1, 42670: 1, 30971: 1, 26247: 1, 37630: 1, 42297: 1, 50236: 1, 16449: 1, 12537: 1, 6261: 1, 4626: 1, 1141: 1, 1508: 1, 11611: 1, 72755: 1, 137129: 1, 110434: 1, 18104: 1, 60194: 1, 28468: 1, 7706: 1, 7005: 1, 12665: 1, 8682: 1, 8702: 1, 33066: 1, 25576: 1, 75419: 1, 19479: 1, 29750: 1, 34953: 1, 4640: 1, 57841: 1, 109502: 1, 29821: 1, 4255: 1, 7733: 1, 2413: 1, 12692: 1, 23020: 1, 77360: 1, 97377: 1, 88101: 1, 35749: 1, 9190: 1, 49983: 1, 27149: 1, 13494: 1, 5050: 1, 15210: 1, 5178: 1, 5287: 1, 3936: 1, 15374: 1, 25733: 1, 2551: 1, 4290: 1, 6748: 1, 4524: 1, 3766: 1, 12856: 1, 5138: 1, 4136: 1, 2854: 1, 5692: 1, 4525: 1, 8908: 1, 10857: 1, 15784: 1, 20075: 1, 9188: 1, 8359: 1, 7740: 1, 5260: 1, 6567: 1, 5377: 1, 7142: 1, 1003: 1, 2439: 1, 3968: 1, 1067: 1, 2312: 1, 3024: 1, 4884: 1, 4276: 1, 6266: 1, 14432: 1, 10849: 1, 3486: 1, 18863: 1, 10004: 1, 3094: 1, 11132: 1, 16107: 1, 7090: 1, 3369: 1, 2016: 1, 2037: 1, 2440: 1, 809: 1, 2175: 1, 957: 1, 3030: 1, 10364: 1, 4724: 1, 10722: 1, 9490: 1, 17010: 1, 19569: 1, 43910: 1, 5187: 1, 2378: 1, 24528: 1, 16356: 1, 75803: 1, 91296: 1, 35795: 1, 56258: 1, 27972: 1, 10626: 1, 11699: 1, 6130: 1, 7888: 1, 275: 1, 6143: 1, 5031: 1, 2885: 1, 3741: 1, 3902: 1, 517: 1, 10169: 1, 5660: 1, 9519: 1, 14547: 1, 8674: 1, 9612: 1, 3574: 1, 5413: 1, 19098: 1, 30201: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(len(image.descriptors) for image in images.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File [bak/snow-man/images-matched.pkl] DO NOT exists\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile [bak/\u001b[39m\u001b[39m{\u001b[39;00mimage_set_name\u001b[39m}\u001b[39;00m\u001b[39m/images-matched.pkl] DO NOT exists\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     get_matches(images)\n\u001b[0;32m     11\u001b[0m     dump_images_bak(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbak/\u001b[39m\u001b[39m{\u001b[39;00mimage_set_name\u001b[39m}\u001b[39;00m\u001b[39m/images-matched.pkl\u001b[39m\u001b[39m\"\u001b[39m, images)\n\u001b[0;32m     12\u001b[0m     \u001b[39m# remove bak/{image_set_name}/sift-features.pkl\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 32\u001b[0m, in \u001b[0;36mget_matches\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     30\u001b[0m CLUSTER_COUNT: Final \u001b[39m=\u001b[39m \u001b[39m400\u001b[39m\n\u001b[0;32m     31\u001b[0m ITER: Final \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> 32\u001b[0m centroids, _ \u001b[39m=\u001b[39m kmeans(all_descriptors, CLUSTER_COUNT, ITER)\n\u001b[0;32m     33\u001b[0m matches_ids: \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[\u001b[39mtuple\u001b[39m[\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m  get_matches_ids([image\u001b[39m.\u001b[39mdescriptors \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images\u001b[39m.\u001b[39mimages], centroids, images\u001b[39m.\u001b[39mimages)\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m i, image \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(images\u001b[39m.\u001b[39mimages):\n",
      "File \u001b[1;32md:\\CUFE\\Year 4\\Semester 2\\GP\\Project\\photogrammetry\\venv\\lib\\site-packages\\scipy\\cluster\\vq.py:476\u001b[0m, in \u001b[0;36mkmeans\u001b[1;34m(obs, k_or_guess, iter, thresh, check_finite, seed)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39miter\u001b[39m):\n\u001b[0;32m    474\u001b[0m     \u001b[39m# the initial code book is randomly selected from observations\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     guess \u001b[39m=\u001b[39m _kpoints(obs, k, rng)\n\u001b[1;32m--> 476\u001b[0m     book, dist \u001b[39m=\u001b[39m _kmeans(obs, guess, thresh\u001b[39m=\u001b[39;49mthresh)\n\u001b[0;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m dist \u001b[39m<\u001b[39m best_dist:\n\u001b[0;32m    478\u001b[0m         best_book \u001b[39m=\u001b[39m book\n",
      "File \u001b[1;32md:\\CUFE\\Year 4\\Semester 2\\GP\\Project\\photogrammetry\\venv\\lib\\site-packages\\scipy\\cluster\\vq.py:304\u001b[0m, in \u001b[0;36m_kmeans\u001b[1;34m(obs, guess, thresh)\u001b[0m\n\u001b[0;32m    301\u001b[0m prev_avg_dists \u001b[39m=\u001b[39m deque([diff], maxlen\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    302\u001b[0m \u001b[39mwhile\u001b[39;00m diff \u001b[39m>\u001b[39m thresh:\n\u001b[0;32m    303\u001b[0m     \u001b[39m# compute membership and distances between obs and code_book\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     obs_code, distort \u001b[39m=\u001b[39m vq(obs, code_book, check_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    305\u001b[0m     prev_avg_dists\u001b[39m.\u001b[39mappend(distort\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m    306\u001b[0m     \u001b[39m# recalc code_book as centroids of associated obs\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. Image Matching\n",
    "if last_state == \"Images Matching Step\":\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/images-matched.pkl\"):\n",
    "        print(f\"File [bak/{image_set_name}/images-matched.pkl] exists\")\n",
    "        if images: \n",
    "            del images\n",
    "        images: Images = load_images_bak(f\"bak/{image_set_name}/images-matched.pkl\")\n",
    "    else:\n",
    "        print(f\"File [bak/{image_set_name}/images-matched.pkl] DO NOT exists\")\n",
    "        get_matches(images)\n",
    "        dump_images_bak(f\"bak/{image_set_name}/images-matched.pkl\", images)\n",
    "        # remove bak/{image_set_name}/sift-features.pkl\n",
    "        if os.path.exists(f\"bak/{image_set_name}/sift-features.pkl\"):\n",
    "            os.remove(f\"bak/{image_set_name}/sift-features.pkl\")\n",
    "            print(f\"File bak/{image_set_name}/sift-features.pkl removed successfully.\")\n",
    "        else:\n",
    "            print(f\"File bak/{image_set_name}/sift-features.pkl does not exist.\")\n",
    "    print(\"Done Image Matching Step...\")\n",
    "    last_state = \"Feature Matching Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Feature Matching\n",
    "if last_state == \"Feature Matching Step\":\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/feature-matching-output.pkl\"):\n",
    "        print(f\"File [bak/{image_set_name}/feature-matching-output.pkl] exists\")\n",
    "        if images: \n",
    "            del images\n",
    "        images: Images = load_images_bak(f\"bak/{image_set_name}/feature-matching-output.pkl\")\n",
    "    else:\n",
    "        print(\"File [bak/{image_set_name}/feature-matching-output.pkl] Do NOT exists\")\n",
    "        # logging.info('----> Processing {image_set_name}...')\n",
    "        data_feature_matching(images)\n",
    "        dump_images_bak(f\"bak/{image_set_name}/feature-matching-output.pkl\", images)\n",
    "        # remove bak/{image_set_name}/images-matched.pkl\n",
    "        if os.path.exists(f\"bak/{image_set_name}/images-matched.pkl\"):\n",
    "            os.remove(f\"bak/{image_set_name}/images-matched.pkl\")\n",
    "            print(f\"File bak/{image_set_name}/images-matched.pkl removed successfully.\")\n",
    "        else:\n",
    "            print(f\"File bak/{image_set_name}/images-matched.pkl does not exist.\")\n",
    "    print(\"Done Feature Matching Step...\")\n",
    "    last_state = \"Point Cloud Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Camera Calibration\n",
    "print(\"Camera Calibration starts ....\")\n",
    "if not os.path.isfile(\"bak/snow-man/checker/K_matrix.pickle\"):\n",
    "    raise IntrinsicParametersNotFoundError(\"Intrinsic parameters not found\")\n",
    "print(\"File bak/snow-man/checker/K_matrix.pickle exists\")\n",
    "with open('bak/snow-man/checker/K_matrix.pickle', 'rb') as f:\n",
    "    K_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Triangulation (3D reconstruction)\n",
    "print(\"Triangulation starts ....\")\n",
    "if last_state == \"Point Cloud Step\":\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/point-cloud.pkl\"):\n",
    "        with open(f\"bak/{image_set_name}/point-cloud.pkl\", 'rb') as f:\n",
    "            points_cloud: np.ndarray = pickle.load(f)\n",
    "    else:\n",
    "        points_cloud: np.ndarray = generate_point_cloud(images, K_matrix)\n",
    "        # Pickle the point cloud\n",
    "        with open(f\"bak/{image_set_name}/point-cloud.pkl\", 'wb') as f:\n",
    "            pickle.dump(points_cloud, f)\n",
    "        # remove bak/{image_set_name}/feature-matching-output.pkl\n",
    "        # if os.path.exists(f\"bak/{image_set_name}/feature-matching-output.pkl\"):\n",
    "        #     os.remove(f\"bak/{image_set_name}/feature-matching-output.pkl\")\n",
    "        #     print(f\"File bak/{image_set_name}/feature-matching-output.pkl removed successfully.\")\n",
    "        # else:\n",
    "        #     print(f\"File bak/{image_set_name}/feature-matching-output.pkl does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Free Memory from images (not tested yet)\n",
    "# mem_usage()\n",
    "\n",
    "# if images: \n",
    "#   print_size(images)\n",
    "#   del images\n",
    "#   print(\"We freed the memory\")\n",
    "# else:\n",
    "#   print(\"Memory was not freed\")\n",
    "\n",
    "# print_size(points_cloud)\n",
    "\n",
    "# mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*(len(image.descriptors) for image in images.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"points_cloud.shape: {points_cloud.shape}\")\n",
    "# Save the point cloud to a file\n",
    "# np.savetxt(f\"output/{image_set_name}/point-cloud.txt\", points_cloud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot points_cloud\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(points_cloud[:,0], points_cloud[:,1], points_cloud[:,2])\n",
    "\n",
    "# ax.set_xlabel('X Label')\n",
    "# ax.set_ylabel('Y Label')\n",
    "# ax.set_zlabel('Z Label')\n",
    "\n",
    "# plt.show()\n",
    "# plt.savefig('points_histo_plt.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statics about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Log to tune.log\n",
    "def log_tune(file_name: str, message: str):\n",
    "    with open(file_name, \"a\") as f:\n",
    "        f.write(f\"{message}\\n\")\n",
    "\n",
    "log_tune(\"tune-before.log\", f\"X<{len(points_cloud[:,0]):,}>: {points_cloud[:,0].min():,} to {points_cloud[:,0].max():,}\")\n",
    "x_counter = Counter(points_cloud[:,0])\n",
    "log_tune(\"tune-before.log\", f\"We have {len(x_counter):,} unique Y values\")\n",
    "log_tune(\"tune-before.log\", f\"Most Common X: {x_counter.most_common(1)}, Least Two Common X: {x_counter.most_common()[:-3:-1]}\")\n",
    "# log_tune(\"tune-before.log\", x_counter)\n",
    "log_tune(\"tune-before.log\", \"-----------------------------------------------------\")\n",
    "log_tune(\"tune-before.log\", f\"Y<{len(points_cloud[:,1]):,}>: {points_cloud[:,1].min():,} to {points_cloud[:,1].max():,}\")\n",
    "y_counter = Counter(points_cloud[:,1])\n",
    "log_tune(\"tune-before.log\", f\"We have {len(y_counter):,} unique Y values\")\n",
    "log_tune(\"tune-before.log\", f\"Most Common Y: {y_counter.most_common(1)}, Least Two Common Y: {y_counter.most_common()[:-3:-1]}\")\n",
    "# log_tune(\"tune-before.log\", y_counter)\n",
    "log_tune(\"tune-before.log\", \"-----------------------------------------------------\")\n",
    "log_tune(\"tune-before.log\", f\"Z<{len(points_cloud[:,2]):,}>: {points_cloud[:,2].min():,} to {points_cloud[:,2].max():,}\")\n",
    "z_counter = Counter(points_cloud[:,2])\n",
    "log_tune(\"tune-before.log\", f\"We have {len(z_counter):,} unique Z values\")\n",
    "log_tune(\"tune-before.log\", f\"Most Common Z: {z_counter.most_common(1)}, Least Two Common Y: {z_counter.most_common()[:-3:-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_points_cloud = [\n",
    "#     point\n",
    "#     for point in points_cloud\n",
    "#     if -10 <= point[0] <= 10\n",
    "#     and -10 <= point[1] <= 10\n",
    "#     and -10 <= point[2] <= 10\n",
    "# ]\n",
    "\n",
    "# log_tune(\"tune-after.log\", f\"Now we have {len(new_points_cloud):,} points\")\n",
    "# new_points_cloud = np.array(new_points_cloud)\n",
    "\n",
    "# # scale z-axis by factor of 10_000\n",
    "# new_points_cloud[:, 2] = new_points_cloud[:, 2] * 10_000\n",
    "\n",
    "# log_tune(\"tune-after.log\", f\"X<{len(new_points_cloud[:,0]):,}>: {new_points_cloud[:,0].min():,} to {new_points_cloud[:,0].max():,}\")\n",
    "# new_x_counter = Counter(new_points_cloud[:,0])\n",
    "# log_tune(\"tune-after.log\", f\"We have {len(new_x_counter):,} unique Y values\")\n",
    "# log_tune(\"tune-after.log\", f\"Most Common X: {new_x_counter.most_common(1)}, Least Two Common X: {new_x_counter.most_common()[:-3:-1]}\")\n",
    "# # log_tune(\"tune-after.log\", x_counter)\n",
    "# log_tune(\"tune-after.log\", \"-----------------------------------------------------\")\n",
    "# log_tune(\"tune-after.log\", f\"Y<{len(new_points_cloud[:,1]):,}>: {new_points_cloud[:,1].min():,} to {new_points_cloud[:,1].max():,}\")\n",
    "# new_y_counter = Counter(new_points_cloud[:,1])\n",
    "# log_tune(\"tune-after.log\", f\"We have {len(new_y_counter):,} unique Y values\")\n",
    "# log_tune(\"tune-after.log\", f\"Most Common Y: {new_y_counter.most_common(1)}, Least Two Common Y: {new_y_counter.most_common()[:-3:-1]}\")\n",
    "# # log_tune(\"tune-after.log\", y_counter)\n",
    "# log_tune(\"tune-after.log\", \"-----------------------------------------------------\")\n",
    "# log_tune(\"tune-after.log\", f\"Z<{len(new_points_cloud[:,2]):,}>: {new_points_cloud[:,2].min():,} to {new_points_cloud[:,2].max():,}\")\n",
    "# new_z_counter = Counter(new_points_cloud[:,2])\n",
    "# log_tune(\"tune-after.log\", f\"We have {len(new_z_counter):,} unique Z values\")\n",
    "# log_tune(\"tune-after.log\", f\"Most Common Z: {new_z_counter.most_common(1)}, Least Two Common Y: {new_z_counter.most_common()[:-3:-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage()\n",
    "\n",
    "print_size(points_cloud)\n",
    "print_size(x_counter)\n",
    "print_size(y_counter)\n",
    "print_size(z_counter)\n",
    "\n",
    "# print_size(new_points_cloud)\n",
    "# print_size(new_x_counter)\n",
    "# print_size(new_y_counter)\n",
    "# print_size(new_z_counter)\n",
    "\n",
    "# del points_cloud\n",
    "del x_counter\n",
    "del y_counter\n",
    "del z_counter\n",
    "\n",
    "# del new_points_cloud\n",
    "# del new_x_counter\n",
    "# del new_y_counter\n",
    "# del new_z_counter\n",
    "\n",
    "mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# # Cluster the points using DBSCAN algorithm\n",
    "# dbscan = DBSCAN(eps=0.5, min_samples=10).fit(points_cloud)\n",
    "\n",
    "# # Get the cluster labels for each point\n",
    "# labels = dbscan.labels_\n",
    "\n",
    "# # Print all labels\n",
    "# print(\"All labels:\", labels)\n",
    "\n",
    "# # Get the indices of the core points (i.e., points that are part of a dense region)\n",
    "# core_indices = np.where(labels != -1)[0]\n",
    "\n",
    "# # Get the coordinates of the core points\n",
    "# core_points = points_cloud[core_indices, :]\n",
    "\n",
    "# # Get the indices of the outlier points (i.e., points that are not part of any dense region)\n",
    "# outlier_indices = np.where(labels == -1)[0]\n",
    "\n",
    "# # Get the coordinates of the outlier points\n",
    "# outlier_points = points_cloud[outlier_indices, :]\n",
    "\n",
    "# # Print the number of clusters and the number of outlier points\n",
    "# print(\"Number of clusters:\", len(np.unique(labels)) - 1)\n",
    "# print(\"Number of outlier points:\", len(outlier_indices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the histogram of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NUM_PINS: Final[int] = 2_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x_counter = {k: v for k, v in x_counter.items() if -4 < k < 4}\n",
    "# # new_x_counter = Counter(x_counter)\n",
    "# print(f\"We have {len(new_x_counter):,} unique X values\")\n",
    "# print(f\"Most Common X: {new_x_counter.most_common(1)}, Least Two Common X: {new_x_counter.most_common()[:-3:-1]}\")\n",
    "# print(f\"Max X: {max(new_x_counter)}, Min X: {min(new_x_counter)}\")\n",
    "# plt.hist(list(new_x_counter.keys()), weights=list(new_x_counter.values()), bins=NUM_PINS, label='x-axis')\n",
    "# plt.title('X Points Cloud Histogram')\n",
    "# plt.xlabel('Point X Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.savefig('x_points_histo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # plot points_cloud\n",
    "# # import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(new_points_cloud[:,0], new_points_cloud[:,1], new_points_cloud[:,2])\n",
    "\n",
    "# ax.set_xlabel('X Label')\n",
    "# ax.set_ylabel('Y Label')\n",
    "# ax.set_zlabel('Z Label')\n",
    "\n",
    "# plt.show()\n",
    "# plt.savefig('points_histo_plt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_counter = {k: v for k, v in y_counter.items() if -10 < k < 10}\n",
    "# # y_counter = Counter(y_counter)\n",
    "# print(f\"We have {len(new_y_counter):,} unique Y values\")\n",
    "# print(f\"Most Common Y: {new_y_counter.most_common(1)}, Least Two Common Y: {new_y_counter.most_common()[:-3:-1]}\")\n",
    "# print(f\"Max Y: {max(new_y_counter)}, Min Y: {min(new_y_counter)}\")\n",
    "# plt.hist(list(new_y_counter.keys()), weights=list(new_y_counter.values()), bins=NUM_PINS, label='y-axis')\n",
    "# plt.title('Y Points Cloud Histogram')\n",
    "# plt.xlabel('Point Y Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.savefig('y_points_histo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mem_usage()\n",
    "\n",
    "# new_z_counter = {k: v for k, v in new_z_counter.items() if -0.001 < k < 0.001}\n",
    "# new_z_counter = Counter(new_z_counter)\n",
    "# print(f\"We have {len(new_z_counter):,} unique Z values\")\n",
    "# print(f\"Most Common Z: {new_z_counter.most_common(1)}, Least Two Common Z: {new_z_counter.most_common()[:-3:-1]}\")\n",
    "# print(f\"Max Z: {max(new_z_counter)}, Min Z: {min(new_z_counter)}\")\n",
    "# plt.hist(list(new_z_counter.keys()), weights=list(new_z_counter.values()), bins=NUM_PINS, label='z-axis')\n",
    "# plt.title('Z Points Cloud Histogram')\n",
    "# plt.xlabel('Point Z Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.savefig('z_points_histo.png')\n",
    "\n",
    "# mem_usage()\n",
    "# del plt\n",
    "# mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_to_file(filename: str, message: str):\n",
    "#     with open(filename, \"a\") as f:\n",
    "#         f.write(f\"{message}\\n\")\n",
    "\n",
    "# def print_ascii_bar_chart(data, filename, symbol=\"#\"):\n",
    "#     counter = Counter(data).most_common()\n",
    "#     chart = {category: symbol * frequency for category, frequency in counter}\n",
    "#     max_len = max(len(category) for category in chart)\n",
    "#     for category, frequency in chart.items():\n",
    "#         padding = (max_len - len(category)) * \" \"\n",
    "#         log_to_file(filename, f\"{category}{padding} |{frequency}\")\n",
    "# print_ascii_bar_chart(points_cloud[:,0], \"x_values_freq.log\", symbol=\"+\")\n",
    "# print_ascii_bar_chart(points_cloud[:,1], \"y_values_freq.log\", symbol=\"+\")\n",
    "# print_ascii_bar_chart(points_cloud[:,2], \"z_values_freq.log\", symbol=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig, axs = plt.subplots(1, 3, sharey=True, tight_layout=True)\n",
    "# axs[0].hist(points_cloud[:, 0], bins=17_000_000)\n",
    "# axs[1].hist(points_cloud[:, 1], bins=17_000_000)\n",
    "# axs[2].hist(points_cloud[:, 2], bins=17_000_000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Generate point cloud\n",
    "# # point_cloud = np.random.rand(10000, 3)\n",
    "\n",
    "# # Define scaling factor\n",
    "# scale_factor = 2.0\n",
    "\n",
    "# # Scale the point cloud\n",
    "# # scaled_point_cloud = scaled_point_cloud * scale_factor\n",
    "\n",
    "# # Plot histogram of scaled_point_cloud\n",
    "# plt.hist(points_cloud.flatten(), bins=17_000_000, alpha=0.5, label='Before Scaling')\n",
    "# # Plot histogram of scaled_point_cloud\n",
    "# # plt.hist(scaled_point_cloud.flatten(), bins=50, alpha=0.5, label='After Scaling')\n",
    "\n",
    "# # Add titles and labels to the plot\n",
    "# plt.title('Point Cloud Histogram')\n",
    "# plt.xlabel('Point Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_points_cloud = new_points_cloud\n",
    "\n",
    "# new_points_cloud = [\n",
    "#     point\n",
    "#     for point in temp_points_cloud\n",
    "#     if -10 <= point[0] <= 10\n",
    "#     and -10 <= point[1] <= 10\n",
    "#     and -10 <= point[2] <= 10\n",
    "# ]\n",
    "\n",
    "# log_tune(\"tune-after.log\", f\"Now we have {len(new_points_cloud):,} points\")\n",
    "# new_points_cloud = np.array(new_points_cloud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END of Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points_cloud[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as a.STL file\n",
    "o3d.io.write_point_cloud(\"point_cloud.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
