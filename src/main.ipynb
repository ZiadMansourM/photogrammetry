{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from typing import Final, List, Tuple\n",
    "\n",
    "import cv2 as OpenCV\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from numpy.linalg import norm\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from scipy.spatial import Delaunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_rbg(imagePath: str):\n",
    "    return OpenCV.cvtColor(OpenCV.imread(imagePath), OpenCV.COLOR_BGR2RGB)\n",
    "\n",
    "def rgp_to_gray(images):\n",
    "    return [OpenCV.cvtColor(image, OpenCV.COLOR_RGB2GRAY) for image in images]\n",
    "\n",
    "def read_images(folderPath):\n",
    "    files = sorted(os.listdir(folderPath))\n",
    "    return [\n",
    "        read_images_rbg(f\"{folderPath}/{file}\")\n",
    "        for file in files\n",
    "        if \".jpg\" in file\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calibrate_camera(image_set_name, pattern_type='chessboard'):\n",
    "#     # Define the size of the chessboard pattern used for calibration\n",
    "#     pattern_size = (6, 9)\n",
    "\n",
    "#     # Prepare object points\n",
    "#     objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "#     objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "#     # Create empty arrays to store object points and image points from all the calibration images\n",
    "#     objpoints = []\n",
    "#     imgpoints = []\n",
    "\n",
    "#     print(f\"Calibrating camera for image set '{image_set_name}'...\")\n",
    "#     print(f\"Loading calibration images from 'images/{image_set_name}'...\")\n",
    "#     # Load calibration images from the \"images/snow-man\" directory\n",
    "#     images = glob.glob(\"images/snow-man/*.jpg\")\n",
    "\n",
    "#     # Loop through all images\n",
    "#     for fname in images:\n",
    "#         print(f\"Processing image '{fname}'...\")\n",
    "#         # Load the image\n",
    "#         img = OpenCV.imread(fname)\n",
    "#         # Convert the image to grayscale\n",
    "#         gray = OpenCV.cvtColor(img, OpenCV.COLOR_BGR2GRAY)\n",
    "\n",
    "#         # Find the chessboard corners in the image\n",
    "#         ret, corners = OpenCV.findChessboardCorners(gray, pattern_size, None)\n",
    "\n",
    "#         # If the corners are found, add object points and image points to the lists\n",
    "#         if ret == True:\n",
    "#             objpoints.append(objp)\n",
    "#             imgpoints.append(corners)\n",
    "\n",
    "#     # Calibrate the camera and find the camera matrix K\n",
    "#     print(\"Calibrating camera...\")\n",
    "#     ret, K_matrix, distortion_coefficients, rvecs, tvecs = OpenCV.calibrateCamera(\n",
    "#         objpoints,\n",
    "#         imgpoints,\n",
    "#         gray.shape[::-1], \n",
    "#         None, None\n",
    "#     )\n",
    "#     print(\"Camera calibration complete.\")\n",
    "\n",
    "#     if not ret:\n",
    "#         raise CalibrationError('Camera calibration failed')\n",
    "\n",
    "#     return K_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_keypoints(GRAY_IMAGES, SIFT):\n",
    "    keypoints, descriptors = [], []\n",
    "    for i in range(len(GRAY_IMAGES)):\n",
    "        keyPoint, descriptor = SIFT.detectAndCompute(GRAY_IMAGES[i], None)\n",
    "        keypoints.append(np.array(keyPoint))\n",
    "        descriptors.append(np.array(descriptor))\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def convert_keypoints_to_tuples(\n",
    "        keypoints: List[List[OpenCV.KeyPoint]]\n",
    "        ) -> List[List[Tuple[float, float, float, float, int, int]]]:\n",
    "    \"\"\"\n",
    "    Converts a list of lists of cv2.KeyPoint objects to a list of lists of tuples, where each tuple contains the point\n",
    "    coordinates, size, angle, response, octave, and class ID of a keypoint.\n",
    "    That is done because cv2.KeyPoint objects are not serializable. And we aim to use pickle to save the keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints: A list of lists of cv2.KeyPoint objects.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists of tuples, where each tuple contains the point coordinates, size, angle, response, octave, and\n",
    "        class ID of a keypoint.\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"{keypoints[0]=}\")\n",
    "    return [\n",
    "        [\n",
    "            (kp.pt, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) \n",
    "            for kp in kp_list\n",
    "        ] for kp_list in keypoints \n",
    "    ]\n",
    "\n",
    "\n",
    "def load_sift_features(path: str):\n",
    "        with open(path, 'rb') as f:\n",
    "            keypoints_tuple, descriptors = pickle.load(f)\n",
    "        keypoints = convert_tuples_to_keypoints(keypoints_tuple)\n",
    "        return keypoints, descriptors\n",
    "\n",
    "\n",
    "def dump_sift_features(path: str, keypoints, descriptors):\n",
    "    keypoints_tuples = convert_keypoints_to_tuples(keypoints)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump((keypoints_tuples, descriptors), f)\n",
    "\n",
    "\n",
    "def convert_tuples_to_keypoints(\n",
    "        keypoints_tuple: List[List[Tuple[float, float, float, float, int, int]]]\n",
    "        ) -> List[List[OpenCV.KeyPoint]]:\n",
    "    \"\"\"\n",
    "    Converts a list of lists of tuples containing point coordinates, size, angle, response, octave, and class ID of a\n",
    "    keypoint to a list of lists of cv2.KeyPoint objects.\n",
    "    That is done because cv2.KeyPoint objects are not serializable. And we aim to use pickle to save/load the keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints_tuple: A list of lists of tuples containing point coordinates, size, angle, response, octave, and\n",
    "        class ID of a keypoint.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists of cv2.KeyPoint objects.\n",
    "\n",
    "    \"\"\"\n",
    "    return [\n",
    "        [\n",
    "            OpenCV.KeyPoint(x=kp[0][0], y=kp[0][1], size=kp[1], angle=kp[2], response=kp[3], octave=kp[4], class_id=kp[5])\n",
    "            for kp in kp_array\n",
    "        ] for kp_array in keypoints_tuple\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def match_images(descriptors):\n",
    "    all_descriptors = np.concatenate(descriptors)\n",
    "    CLUSTER_COUNT: Final = 400\n",
    "    ITER: Final = 2\n",
    "    centroids, variance = kmeans(all_descriptors, CLUSTER_COUNT, ITER)\n",
    "    return centroids, variance, CLUSTER_COUNT\n",
    "\n",
    "\n",
    "def load_image_matching(path: str):\n",
    "    return joblib.load(path)\n",
    "\n",
    "\n",
    "def dump_image_matching(path: str, CLUSTER_COUNT, centroids):\n",
    "    joblib.dump((CLUSTER_COUNT, centroids), path, compress = 3)\n",
    "\n",
    "\n",
    "def get_visual_words(descriptors, centroids):\n",
    "    visual_words = []\n",
    "    for descriptor in descriptors:\n",
    "        words, _ = vq(descriptor, centroids)\n",
    "        visual_words.append(words)\n",
    "    return visual_words\n",
    "\n",
    "\n",
    "def get_frequency_vectors(visual_words, CLUSTER_COUNT):\n",
    "    frequency_vectors = []\n",
    "    for img_words in visual_words:\n",
    "        histogram = np.zeros(CLUSTER_COUNT)\n",
    "        for word in img_words:\n",
    "            histogram[word] += 1\n",
    "        frequency_vectors.append(histogram)\n",
    "    return np.stack(frequency_vectors)\n",
    "\n",
    "\n",
    "def get_tf_idf(frequency_vectors, IMAGES_COUNT):\n",
    "    df = np.sum(frequency_vectors > 0, axis = 0)\n",
    "    idf = np.log(IMAGES_COUNT/df)\n",
    "    return frequency_vectors * idf\n",
    "\n",
    "\n",
    "def search_matches(i, top_clusters, tf_idf):\n",
    "    b = tf_idf\n",
    "    a = tf_idf[i]\n",
    "    b_subset = b[:tf_idf.shape[0]]\n",
    "    cosine_similarity = np.dot(a, b_subset.T)/(norm(a) * norm(b_subset, axis=1))\n",
    "    idx = np.argsort(-cosine_similarity)[:top_clusters]\n",
    "    return list(zip(idx, cosine_similarity[idx]))\n",
    "\n",
    "\n",
    "def get_matches_ids(descriptors, centroids, gray_images, images):\n",
    "    visual_words = get_visual_words(descriptors, centroids)\n",
    "    frequency_vectors = get_frequency_vectors(visual_words, centroids.shape[0])\n",
    "    \"\"\" tf_idf: Term Frequency-Inverse Document Frequency \"\"\"\n",
    "    tf_idf = get_tf_idf(frequency_vectors, len(gray_images))\n",
    "    return [\n",
    "        search_matches(i, 10, tf_idf) \n",
    "        for i in range(len(images))\n",
    "    ]\n",
    "\n",
    "\n",
    "def feature_matching(img_id_one, img_id_two, descriptors):\n",
    "    matcher = OpenCV.BFMatcher()\n",
    "    return matcher.match(descriptors[img_id_one], descriptors[img_id_two])\n",
    "\n",
    "\n",
    "def data_feature_matching(matchesIDs, Sdescriptors):\n",
    "    num_images = len(Sdescriptors)\n",
    "    checked = np.zeros((num_images, num_images), dtype=int)\n",
    "    feature_matches_list = []\n",
    "    for imageID in range(len(matchesIDs)):\n",
    "        logging.info(f\"---------- START Matches for: {str(imageID)}\")\n",
    "        for i, (matchedID, probability) in enumerate(matchesIDs[imageID]):\n",
    "            if ((checked[imageID][matchedID] == 0 or checked[matchedID][imageID] == 0) and imageID != matchedID and probability > 0.93):\n",
    "                start_time = time.time()\n",
    "                feature_matches_list.append([imageID, matchedID, feature_matching(imageID, matchedID, Sdescriptors)])\n",
    "                checked[imageID][matchedID], checked[matchedID][imageID] = 1, 1\n",
    "                logging.info(f\"done [{i}/{len(matchesIDs[imageID])}] in {(time.time() - start_time):.4f}: {str(imageID)} - {str(matchedID)}\")\n",
    "        # Flush the log file force write to disk\n",
    "        logging.shutdown()\n",
    "    return feature_matches_list\n",
    "\n",
    "\n",
    "def convert_matches_to_dicts(matches):\n",
    "    match_dicts = []\n",
    "    for match in matches:\n",
    "        match_dict = {'queryIdx': match.queryIdx, 'trainIdx': match.trainIdx, 'distance': match.distance}\n",
    "        match_dicts.append(match_dict)\n",
    "    return match_dicts\n",
    "\n",
    "\n",
    "def load_feature_matching(path: str):\n",
    "    with open(path, 'rb') as f:\n",
    "        feature_matches_dicts = pickle.load(f)\n",
    "    feature_matches = []\n",
    "    for match_dict in feature_matches_dicts:\n",
    "        matches = [\n",
    "            OpenCV.DMatch(\n",
    "                match['queryIdx'], \n",
    "                match['trainIdx'], \n",
    "                match['distance']\n",
    "            ) for match in match_dict[2]\n",
    "        ]\n",
    "        feature_matches.append([match_dict[0], match_dict[1], matches])\n",
    "    return feature_matches\n",
    "\n",
    "\n",
    "def dump_feature_matching(path: str, feature_matches):\n",
    "    matches_dicts = [\n",
    "        [\n",
    "            match[0],\n",
    "            match[1], \n",
    "            convert_matches_to_dicts(match[2])\n",
    "        ] for match in feature_matches\n",
    "    ]\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(matches_dicts, f)\n",
    "\n",
    "\n",
    "def triangulatePoints(P1, P2, pts1, pts2):\n",
    "    \"\"\"\n",
    "    Triangulates the given matching points from two images using the given camera matrices.\n",
    "\n",
    "    Parameters:\n",
    "    P1 (numpy.ndarray): 3x4 camera matrix of the first image.\n",
    "    P2 (numpy.ndarray): 3x4 camera matrix of the second image.\n",
    "    pts1 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the first image.\n",
    "    pts2 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the second image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the triangulated 3D points.\n",
    "    \"\"\"\n",
    "    pts4D = OpenCV.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "    pts4D /= pts4D[3]\n",
    "    return pts4D[:3].T\n",
    "\n",
    "\n",
    "def generate_point_cloud(feature_matches_list, K_matrix):\n",
    "    \"\"\"\n",
    "    Generates a cloud of 3D points using triangulation from feature matches and camera calibration matrix.\n",
    "\n",
    "    Parameters:\n",
    "    feature_matches_list (list): List of feature matches between images.\n",
    "    K_matrix (numpy.ndarray): 3x3 camera calibration matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the cloud of 3D points.\n",
    "    \"\"\"\n",
    "    point_cloud = []\n",
    "    for match in feature_matches_list:\n",
    "        img1, img2, matches = match\n",
    "        pts1 = np.float32([kp.pt for kp in matches[0]])\n",
    "        pts2 = np.float32([kp.pt for kp in matches[1]])\n",
    "        E, _ = OpenCV.findEssentialMat(pts1, pts2, K_matrix)\n",
    "        R1, R2, t = OpenCV.decomposeEssentialMat(E)\n",
    "\n",
    "        for i in range(len(R1)):\n",
    "            P1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "            P2 = np.hstack((R1[i], t))\n",
    "            pts_3d = triangulatePoints(K_matrix.dot(P1), K_matrix.dot(P2), pts1, pts2)\n",
    "            point_cloud.append(pts_3d)\n",
    "    return np.concatenate(point_cloud, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome ScanMate...\n",
      "Images loaded successfully\n",
      "Gray Images created successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome ScanMate...\")\n",
    "image_set_name = \"snow-man\"\n",
    "# 1. Load Images\n",
    "images = read_images(f\"images/{image_set_name}\")\n",
    "print(\"Images loaded successfully\")\n",
    "gray_images = rgp_to_gray(images)\n",
    "print(\"Gray Images created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File [bak/snow-man/sift-features.pkl] exists\n",
      "Feature Extraction: SIFT DONE...\n"
     ]
    }
   ],
   "source": [
    "# 2. Feature Extraction: SIFT\n",
    "sift = OpenCV.SIFT_create()\n",
    "if os.path.isfile(f\"bak/{image_set_name}/sift-features.pkl\"):\n",
    "    print(f\"File [bak/{image_set_name}/sift-features.pkl] exists\")\n",
    "    keypoints, descriptors = load_sift_features(f\"bak/{image_set_name}/sift-features.pkl\")\n",
    "else:\n",
    "    print(\"File [bak/{image_set_name}/sift-features.pkl] DO NOT exists\")\n",
    "    keypoints, descriptors = get_images_keypoints(gray_images, sift)\n",
    "    dump_sift_features(f\"bak/{image_set_name}/sift-features.pkl\", keypoints, descriptors)\n",
    "print(\"Feature Extraction: SIFT DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File [bak/snow-man/image-matching-centroids.pkl] exists\n",
      "Done Image Matching Step...\n"
     ]
    }
   ],
   "source": [
    "# 3. Image Matching\n",
    "if os.path.isfile(f\"bak/{image_set_name}/image-matching-centroids.pkl\"):\n",
    "    print(f\"File [bak/{image_set_name}/image-matching-centroids.pkl] exists\")\n",
    "    CLUSTER_COUNT, centroids = load_image_matching(f\"bak/{image_set_name}/image-matching-centroids.pkl\")\n",
    "else:\n",
    "    print(f\"File [bak/{image_set_name}/image-matching-centroids.pkl] DO NOT exists\")\n",
    "    centroids, variance, CLUSTER_COUNT = match_images(descriptors)\n",
    "    dump_image_matching(f\"bak/{image_set_name}/image-matching-centroids.pkl\", CLUSTER_COUNT, centroids)\n",
    "matches_ids = get_matches_ids(descriptors, centroids, gray_images, images)\n",
    "print(\"Done Image Matching Step...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File [bak/snow-man/feature-matching-output.pkl] exists\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Matching\n",
    "if os.path.isfile(f\"bak/{image_set_name}/feature-matching-output.pkl\"):\n",
    "    print(f\"File [bak/{image_set_name}/feature-matching-output.pkl] exists\")\n",
    "    feature_matches = load_feature_matching(f\"bak/{image_set_name}/feature-matching-output.pkl\")\n",
    "else:\n",
    "    print(\"File [bak/{image_set_name}/feature-matching-output.pkl] Do NOT exists\")\n",
    "    logging.info('----> Processing {image_set_name}...')\n",
    "    feature_matches = data_feature_matching(matches_ids, descriptors)\n",
    "    dump_feature_matching(f\"bak/{image_set_name}/feature-matching-output.pkl\", feature_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# # Set up logging configuration\n",
    "# logging.basicConfig(filename='calibrate-camera.log', level=logging.INFO,\n",
    "#                     format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# import time\n",
    "\n",
    "# # Define a function that processes a single image and returns the object and image points\n",
    "# def process_image(fname, pattern_size, objp):\n",
    "#     start_time = time.time()\n",
    "#     # Load the image\n",
    "#     img = OpenCV.imread(fname)\n",
    "#     # Convert the image to grayscale\n",
    "#     gray = OpenCV.cvtColor(img, OpenCV.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Find the chessboard corners in the image\n",
    "#     ret, corners = OpenCV.findChessboardCorners(gray, pattern_size, None)\n",
    "\n",
    "#     # print(f\"Done in {time.time()-start_time:.2f} seconds. Image:  '{fname}'...\")\n",
    "#     logging.info(f\"Done in {time.time()-start_time:.2f} seconds. Image:  '{fname}'...\")\n",
    "#     logging.shutdown()\n",
    "\n",
    "#     # If the corners are found, add object points and image points to the lists\n",
    "#     return objp, corners, gray if ret == True and gray is not None else None\n",
    "\n",
    "# def calibrate_camera_process_images(image_set_name, pattern_type='chessboard'):\n",
    "#     logging.info(f\"Calibrating camera for image set '{image_set_name}'...\")\n",
    "#     print(f\"Calibrating camera for image set '{image_set_name}'...\")\n",
    "#     # Define the size of the chessboard pattern used for calibration\n",
    "#     pattern_size = (6, 9)\n",
    "\n",
    "#     # Prepare object points\n",
    "#     objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "#     objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "#     # Create empty arrays to store object points and image points from all the calibration images\n",
    "#     objpoints = []\n",
    "#     imgpoints = []\n",
    "\n",
    "#     # Load calibration images from the \"images/snow-man\" directory\n",
    "#     print(f\"Loading calibration images from 'images/{image_set_name}'...\")\n",
    "#     images = glob.glob(\"images/snow-man/*.jpg\")\n",
    "\n",
    "#     # Process the images in parallel using joblib\n",
    "#     print(\"Processing images in parallel...\")\n",
    "#     results = Parallel(n_jobs=-1)(delayed(process_image)(fname, pattern_size, objp) for fname in images)\n",
    "#     print(\"Processing complete.\")\n",
    "\n",
    "#     return results, objpoints, imgpoints\n",
    "\n",
    "# def get_camera_calibration_matrix(results, objpoints, imgpoints):\n",
    "#     # Collect the object and image points from the valid results\n",
    "#     print(\"Collecting object and image points...\")\n",
    "#     for result in results:\n",
    "#         if result is not None:\n",
    "#             objpoints.append(result[0])\n",
    "#             imgpoints.append(result[1])\n",
    "#             gray = result[2]\n",
    "#             if not gray:\n",
    "#                 print(result[1])\n",
    "#                 print(gray is None)\n",
    "#                 print(\"WE Are fucked\")\n",
    "#     print(\"Collection complete.\")\n",
    "\n",
    "#     # Calibrate the camera and find the camera matrix K\n",
    "#     print(\"Calibrating camera...\")\n",
    "#     ret, K_matrix, distortion_coefficients, rvecs, tvecs = OpenCV.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "#     print(\"Camera calibration complete.\")\n",
    "\n",
    "#     if not ret:\n",
    "#         raise CalibrationError('Camera calibration failed')\n",
    "\n",
    "#     return K_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera_process_images(image_set_name, pattern_type='chessboard'):\n",
    "    # Define the size of the chessboard pattern used for calibration\n",
    "    pattern_size = (6, 9)\n",
    "\n",
    "    def get_image_sizes(directory):\n",
    "        sizes = {}\n",
    "        images = glob.glob(f\"{directory}/*.jpg\")\n",
    "\n",
    "        for fname in images:\n",
    "            img = OpenCV.imread(fname)\n",
    "            size = tuple(img.shape[:2])\n",
    "            if size not in sizes:\n",
    "                sizes[size] = [fname]\n",
    "            else:\n",
    "                sizes[size].append(fname)\n",
    "\n",
    "        return sizes\n",
    "\n",
    "    sizes_dict = get_image_sizes(f\"images/{image_set_name}\")\n",
    "\n",
    "    process_images_list = []\n",
    "    print(f\"Start processing images for image set '{image_set_name}'...\")\n",
    "    for size, image_list in sizes_dict.items():\n",
    "        with open(\"calibrate-camera.log\", \"a\") as f:\n",
    "            f.write(f\"Processing images with size {size}...\\n\")\n",
    "        # Prepare object points\n",
    "        objp = np.zeros(\n",
    "            (pattern_size[0] * pattern_size[1], 3), \n",
    "            np.float32\n",
    "        )\n",
    "        objp[:, :2] = np.mgrid[\n",
    "            0:pattern_size[0], \n",
    "            0:pattern_size[1]\n",
    "        ].T.reshape(-1, 2)\n",
    "        # Create empty arrays to store object points and image points from all the calibration images\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        # Loop through all images\n",
    "        for i, fname in enumerate(image_list):\n",
    "            start_time = time.time()\n",
    "            # Load the image\n",
    "            img = OpenCV.imread(fname)\n",
    "            # Convert the image to grayscale\n",
    "            gray = OpenCV.cvtColor(img, OpenCV.COLOR_BGR2GRAY)\n",
    "            # Find the chessboard corners in the image\n",
    "            ret, corners = OpenCV.findChessboardCorners(gray, pattern_size, None)\n",
    "            # If the corners are found, add object points and image points to the lists\n",
    "            if ret == True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "                with open(\"calibrate-camera.log\", \"a\") as f:\n",
    "                    f.write(f\"Done image {i+1} of {len(image_list)} in {time.time()-start_time:.2f}...\\n\")\n",
    "            else:\n",
    "                with open(\"calibrate-camera.log\", \"a\") as f:\n",
    "                    f.write(f\"FAILED image {i+1} of {len(image_list)} in {time.time()-start_time:.2f}...\\n\")\n",
    "        process_images_list.append((size, objpoints, imgpoints))\n",
    "    return process_images_list\n",
    "        \n",
    "def get_camera_calibration_matrix(objpoints, imgpoints, size):\n",
    "    # Calibrate the camera and find the camera matrix K\n",
    "    start_time = time.time()\n",
    "    with open(\"calibrate-camera.log\", \"a\") as f:\n",
    "        f.write(f\"Started matrix calc for {size}...\\n\")\n",
    "    ret, K_matrix, distortion_coefficients, rvecs, tvecs = OpenCV.calibrateCamera(objpoints, imgpoints, size, None, None)\n",
    "    if not ret:\n",
    "        raise CalibrationError('Camera calibration failed')\n",
    "    with open(\"calibrate-camera.log\", \"a\") as f:\n",
    "        f.write(f\"DONE matrix calc for {size} in {time.time()-start_time:.2f}...\\n\")\n",
    "    return K_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Calibration starts ....\n",
      "Start processing images for image set 'snow-man'...\n",
      "Camera Calibration ends ....\n",
      "len(process_images_list)=2\n"
     ]
    }
   ],
   "source": [
    "# 5. Camera Calibration\n",
    "print(\"Camera Calibration starts ....\")\n",
    "process_images_list = calibrate_camera_process_images(\"snow-man\")\n",
    "print(\"Camera Calibration ends ....\")\n",
    "print(f\"{len(process_images_list)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bak/snow-man/calibration.pkl\", 'wb') as f:\n",
    "    pickle.dump(process_images_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(process_images_list)=2\n"
     ]
    }
   ],
   "source": [
    "with open(\"bak/snow-man/calibration.pkl\", 'rb') as f:\n",
    "    process_images_list = pickle.load(f)\n",
    "print(f\"{len(process_images_list)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating camera for image set 'snow-man' with image size (2604, 4624)...\n",
      "<class 'tuple'> (2604, 4624)\n",
      "<class 'list'> 0\n",
      "<class 'list'> 0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:3749: error: (-215:Assertion failed) nimages > 0 in function 'calibrateCameraRO'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(objpoints), \u001b[39mlen\u001b[39m(objpoints))\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(imgpoints), \u001b[39mlen\u001b[39m(imgpoints))\n\u001b[0;32m----> 7\u001b[0m K_matrix \u001b[39m=\u001b[39m get_camera_calibration_matrix(objpoints, imgpoints, size)\n\u001b[1;32m      8\u001b[0m K_matries_list\u001b[39m.\u001b[39mappend(size, K_matrix)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera calibration complete.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[75], line 61\u001b[0m, in \u001b[0;36mget_camera_calibration_matrix\u001b[0;34m(objpoints, imgpoints, size)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcalibrate-camera.log\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     60\u001b[0m     f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarted matrix calc for \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m ret, K_matrix, distortion_coefficients, rvecs, tvecs \u001b[39m=\u001b[39m OpenCV\u001b[39m.\u001b[39;49mcalibrateCamera(objpoints, imgpoints, size, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n\u001b[1;32m     63\u001b[0m     \u001b[39mraise\u001b[39;00m CalibrationError(\u001b[39m'\u001b[39m\u001b[39mCamera calibration failed\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/calib3d/src/calibration.cpp:3749: error: (-215:Assertion failed) nimages > 0 in function 'calibrateCameraRO'\n"
     ]
    }
   ],
   "source": [
    "K_matries_list = []\n",
    "for size, objpoints, imgpoints in process_images_list:\n",
    "    print(f\"Calibrating camera for image set '{image_set_name}' with image size {size}...\")\n",
    "    print(type(size), size)\n",
    "    print(type(objpoints), len(objpoints))\n",
    "    print(type(imgpoints), len(imgpoints))\n",
    "    K_matrix = get_camera_calibration_matrix(objpoints, imgpoints, size)\n",
    "    K_matries_list.append(size, K_matrix)\n",
    "    print(\"Camera calibration complete.\")\n",
    "\n",
    "print(\"Camera Calibration ends ....\")\n",
    "for size, K_matrix in K_matries_list:\n",
    "    print(f\"K_matrix for image size {size} is \\n {K_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"bak/snow-man/calibration.pkl\", 'wb') as f:\n",
    "#     pickle.dump((objpoints, imgpoints, gray), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"bak/snow-man/calibration.pkl\", 'rb') as f:\n",
    "#     objpoints, imgpoints, gray = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_matrix = get_camera_calibration_matrix(objpoints, imgpoints, gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Triangulation (3D reconstruction)\n",
    "print(\"Triangulation starts ....\")\n",
    "points_cloud = generate_point_cloud(feature_matches, K_matrix)\n",
    "np.savetxt(\"points_cloud.txt\", points_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. generate mesh\n",
    "print(\"Generate mesh ....\")\n",
    "tri = Delaunay(points_cloud)\n",
    "mesh = trimesh.Trimesh(points_cloud, tri.simplices)\n",
    "mesh = mesh.simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. output .obj, .stl and .ply files\n",
    "print(\"Generate mesh ....\")\n",
    "mesh.export(f\"output/{image_set_name}/snow_man.obj\")\n",
    "mesh.export(f\"output/{image_set_name}/snow_man.stl\")\n",
    "mesh.export(f\"output/{image_set_name}/snow_man.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
