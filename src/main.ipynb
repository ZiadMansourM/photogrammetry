{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/ziadh/Desktop/college/gp/src/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from typing import Final, List, Tuple\n",
    "\n",
    "import cv2 as OpenCV\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from numpy.linalg import norm\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from scipy.spatial import Delaunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/ziadh/Desktop/college/gp/src/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class CalibrationError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/ziadh/Desktop/college/gp/src/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def read_images_rbg(imagePath: str):\n",
    "    return OpenCV.cvtColor(OpenCV.imread(imagePath), OpenCV.COLOR_BGR2RGB)\n",
    "\n",
    "def rgp_to_gray(images):\n",
    "    return [OpenCV.cvtColor(image, OpenCV.COLOR_RGB2GRAY) for image in images]\n",
    "\n",
    "def read_images(folderPath):\n",
    "    files = sorted(os.listdir(folderPath))\n",
    "    return [\n",
    "        read_images_rbg(f\"{folderPath}/{file}\")\n",
    "        for file in files\n",
    "        if \".jpg\" in file\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/ziadh/Desktop/college/gp/src/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# def calibrate_camera(image_set_name, pattern_type='chessboard'):\n",
    "#     # Define the size of the chessboard pattern used for calibration\n",
    "#     pattern_size = (6, 9)\n",
    "\n",
    "#     # Prepare object points\n",
    "#     objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "#     objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "#     # Create empty arrays to store object points and image points from all the calibration images\n",
    "#     objpoints = []\n",
    "#     imgpoints = []\n",
    "\n",
    "#     print(f\"Calibrating camera for image set '{image_set_name}'...\")\n",
    "#     print(f\"Loading calibration images from 'images/{image_set_name}'...\")\n",
    "#     # Load calibration images from the \"images/snow-man\" directory\n",
    "#     images = glob.glob(\"images/snow-man/*.jpg\")\n",
    "\n",
    "#     # Loop through all images\n",
    "#     for fname in images:\n",
    "#         print(f\"Processing image '{fname}'...\")\n",
    "#         # Load the image\n",
    "#         img = OpenCV.imread(fname)\n",
    "#         # Convert the image to grayscale\n",
    "#         gray = OpenCV.cvtColor(img, OpenCV.COLOR_BGR2GRAY)\n",
    "\n",
    "#         # Find the chessboard corners in the image\n",
    "#         ret, corners = OpenCV.findChessboardCorners(gray, pattern_size, None)\n",
    "\n",
    "#         # If the corners are found, add object points and image points to the lists\n",
    "#         if ret == True:\n",
    "#             objpoints.append(objp)\n",
    "#             imgpoints.append(corners)\n",
    "\n",
    "#     # Calibrate the camera and find the camera matrix K\n",
    "#     print(\"Calibrating camera...\")\n",
    "#     ret, K_matrix, distortion_coefficients, rvecs, tvecs = OpenCV.calibrateCamera(\n",
    "#         objpoints,\n",
    "#         imgpoints,\n",
    "#         gray.shape[::-1], \n",
    "#         None, None\n",
    "#     )\n",
    "#     print(\"Camera calibration complete.\")\n",
    "\n",
    "#     if not ret:\n",
    "#         raise CalibrationError('Camera calibration failed')\n",
    "\n",
    "#     return K_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def calibrate_camera(image_set_name, pattern_type='chessboard'):\n",
    "    # Define the size of the chessboard pattern used for calibration\n",
    "    pattern_size = (6, 9)\n",
    "\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "    # Create empty arrays to store object points and image points from all the calibration images\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "\n",
    "    # Load calibration images from the \"images/snow-man\" directory\n",
    "    images = glob.glob(\"images/snow-man/*.jpg\")\n",
    "\n",
    "    # Define a function that processes a single image and returns the object and image points\n",
    "    def process_image(fname):\n",
    "        # Load the image\n",
    "        img = OpenCV.imread(fname)\n",
    "        # Convert the image to grayscale\n",
    "        gray = OpenCV.cvtColor(img, OpenCV.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners in the image\n",
    "        ret, corners = OpenCV.findChessboardCorners(gray, pattern_size, None)\n",
    "\n",
    "        # If the corners are found, add object points and image points to the lists\n",
    "        return (objp, corners) if ret == True else None\n",
    "\n",
    "    # Process the images in parallel using joblib\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_image)(fname) for fname in images)\n",
    "\n",
    "    # Collect the object and image points from the valid results\n",
    "    for result in results:\n",
    "        if result is not None:\n",
    "            objpoints.append(result[0])\n",
    "            imgpoints.append(result[1])\n",
    "\n",
    "    # Calibrate the camera and find the camera matrix K\n",
    "    ret, K_matrix, distortion_coefficients, rvecs, tvecs = OpenCV.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    if not ret:\n",
    "        raise CalibrationError('Camera calibration failed')\n",
    "\n",
    "    return K_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/ziadh/Desktop/college/gp/src/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def get_images_keypoints(GRAY_IMAGES, SIFT):\n",
    "    keypoints, descriptors = [], []\n",
    "    for i in range(len(GRAY_IMAGES)):\n",
    "        keyPoint, descriptor = SIFT.detectAndCompute(GRAY_IMAGES[i], None)\n",
    "        keypoints.append(np.array(keyPoint))\n",
    "        descriptors.append(np.array(descriptor))\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def convert_keypoints_to_tuples(\n",
    "        keypoints: List[List[OpenCV.KeyPoint]]\n",
    "        ) -> List[List[Tuple[float, float, float, float, int, int]]]:\n",
    "    \"\"\"\n",
    "    Converts a list of lists of cv2.KeyPoint objects to a list of lists of tuples, where each tuple contains the point\n",
    "    coordinates, size, angle, response, octave, and class ID of a keypoint.\n",
    "    That is done because cv2.KeyPoint objects are not serializable. And we aim to use pickle to save the keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints: A list of lists of cv2.KeyPoint objects.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists of tuples, where each tuple contains the point coordinates, size, angle, response, octave, and\n",
    "        class ID of a keypoint.\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"{keypoints[0]=}\")\n",
    "    return [\n",
    "        [\n",
    "            (kp.pt, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) \n",
    "            for kp in kp_list\n",
    "        ] for kp_list in keypoints \n",
    "    ]\n",
    "\n",
    "\n",
    "def load_sift_features(path: str):\n",
    "        with open(path, 'rb') as f:\n",
    "            keypoints_tuple, descriptors = pickle.load(f)\n",
    "        keypoints = convert_tuples_to_keypoints(keypoints_tuple)\n",
    "        return keypoints, descriptors\n",
    "\n",
    "\n",
    "def dump_sift_features(path: str, keypoints, descriptors):\n",
    "    keypoints_tuples = convert_keypoints_to_tuples(keypoints)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump((keypoints_tuples, descriptors), f)\n",
    "\n",
    "\n",
    "def convert_tuples_to_keypoints(\n",
    "        keypoints_tuple: List[List[Tuple[float, float, float, float, int, int]]]\n",
    "        ) -> List[List[OpenCV.KeyPoint]]:\n",
    "    \"\"\"\n",
    "    Converts a list of lists of tuples containing point coordinates, size, angle, response, octave, and class ID of a\n",
    "    keypoint to a list of lists of cv2.KeyPoint objects.\n",
    "    That is done because cv2.KeyPoint objects are not serializable. And we aim to use pickle to save/load the keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints_tuple: A list of lists of tuples containing point coordinates, size, angle, response, octave, and\n",
    "        class ID of a keypoint.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists of cv2.KeyPoint objects.\n",
    "\n",
    "    \"\"\"\n",
    "    return [\n",
    "        [\n",
    "            OpenCV.KeyPoint(x=kp[0][0], y=kp[0][1], size=kp[1], angle=kp[2], response=kp[3], octave=kp[4], class_id=kp[5])\n",
    "            for kp in kp_array\n",
    "        ] for kp_array in keypoints_tuple\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def match_images(descriptors):\n",
    "    all_descriptors = np.concatenate(descriptors)\n",
    "    CLUSTER_COUNT: Final = 400\n",
    "    ITER: Final = 2\n",
    "    centroids, variance = kmeans(all_descriptors, CLUSTER_COUNT, ITER)\n",
    "    return centroids, variance, CLUSTER_COUNT\n",
    "\n",
    "\n",
    "def load_image_matching(path: str):\n",
    "    return joblib.load(path)\n",
    "\n",
    "\n",
    "def dump_image_matching(path: str, CLUSTER_COUNT, centroids):\n",
    "    joblib.dump((CLUSTER_COUNT, centroids), path, compress = 3)\n",
    "\n",
    "\n",
    "def get_visual_words(descriptors, centroids):\n",
    "    visual_words = []\n",
    "    for descriptor in descriptors:\n",
    "        words, _ = vq(descriptor, centroids)\n",
    "        visual_words.append(words)\n",
    "    return visual_words\n",
    "\n",
    "\n",
    "def get_frequency_vectors(visual_words, CLUSTER_COUNT):\n",
    "    frequency_vectors = []\n",
    "    for img_words in visual_words:\n",
    "        histogram = np.zeros(CLUSTER_COUNT)\n",
    "        for word in img_words:\n",
    "            histogram[word] += 1\n",
    "        frequency_vectors.append(histogram)\n",
    "    return np.stack(frequency_vectors)\n",
    "\n",
    "\n",
    "def get_tf_idf(frequency_vectors, IMAGES_COUNT):\n",
    "    df = np.sum(frequency_vectors > 0, axis = 0)\n",
    "    idf = np.log(IMAGES_COUNT/df)\n",
    "    return frequency_vectors * idf\n",
    "\n",
    "\n",
    "def search_matches(i, top_clusters, tf_idf):\n",
    "    b = tf_idf\n",
    "    a = tf_idf[i]\n",
    "    b_subset = b[:tf_idf.shape[0]]\n",
    "    cosine_similarity = np.dot(a, b_subset.T)/(norm(a) * norm(b_subset, axis=1))\n",
    "    idx = np.argsort(-cosine_similarity)[:top_clusters]\n",
    "    return list(zip(idx, cosine_similarity[idx]))\n",
    "\n",
    "\n",
    "def get_matches_ids(descriptors, centroids, gray_images, images):\n",
    "    visual_words = get_visual_words(descriptors, centroids)\n",
    "    frequency_vectors = get_frequency_vectors(visual_words, centroids.shape[0])\n",
    "    \"\"\" tf_idf: Term Frequency-Inverse Document Frequency \"\"\"\n",
    "    tf_idf = get_tf_idf(frequency_vectors, len(gray_images))\n",
    "    return [\n",
    "        search_matches(i, 10, tf_idf) \n",
    "        for i in range(len(images))\n",
    "    ]\n",
    "\n",
    "\n",
    "def feature_matching(img_id_one, img_id_two, descriptors):\n",
    "    matcher = OpenCV.BFMatcher()\n",
    "    return matcher.match(descriptors[img_id_one], descriptors[img_id_two])\n",
    "\n",
    "\n",
    "def data_feature_matching(matchesIDs, Sdescriptors):\n",
    "    num_images = len(Sdescriptors)\n",
    "    checked = np.zeros((num_images, num_images), dtype=int)\n",
    "    feature_matches_list = []\n",
    "    for imageID in range(len(matchesIDs)):\n",
    "        logging.info(f\"---------- START Matches for: {str(imageID)}\")\n",
    "        for i, (matchedID, probability) in enumerate(matchesIDs[imageID]):\n",
    "            if ((checked[imageID][matchedID] == 0 or checked[matchedID][imageID] == 0) and imageID != matchedID and probability > 0.93):\n",
    "                start_time = time.time()\n",
    "                feature_matches_list.append([imageID, matchedID, feature_matching(imageID, matchedID, Sdescriptors)])\n",
    "                checked[imageID][matchedID], checked[matchedID][imageID] = 1, 1\n",
    "                logging.info(f\"done [{i}/{len(matchesIDs[imageID])}] in {(time.time() - start_time):.4f}: {str(imageID)} - {str(matchedID)}\")\n",
    "        # Flush the log file force write to disk\n",
    "        logging.shutdown()\n",
    "    return feature_matches_list\n",
    "\n",
    "\n",
    "def convert_matches_to_dicts(matches):\n",
    "    match_dicts = []\n",
    "    for match in matches:\n",
    "        match_dict = {'queryIdx': match.queryIdx, 'trainIdx': match.trainIdx, 'distance': match.distance}\n",
    "        match_dicts.append(match_dict)\n",
    "    return match_dicts\n",
    "\n",
    "\n",
    "def load_feature_matching(path: str):\n",
    "    with open(path, 'rb') as f:\n",
    "        feature_matches_dicts = pickle.load(f)\n",
    "    feature_matches = []\n",
    "    for match_dict in feature_matches_dicts:\n",
    "        matches = [\n",
    "            OpenCV.DMatch(\n",
    "                match['queryIdx'], \n",
    "                match['trainIdx'], \n",
    "                match['distance']\n",
    "            ) for match in match_dict[2]\n",
    "        ]\n",
    "        feature_matches.append([match_dict[0], match_dict[1], matches])\n",
    "    return feature_matches\n",
    "\n",
    "\n",
    "def dump_feature_matching(path: str, feature_matches):\n",
    "    matches_dicts = [\n",
    "        [\n",
    "            match[0],\n",
    "            match[1], \n",
    "            convert_matches_to_dicts(match[2])\n",
    "        ] for match in feature_matches\n",
    "    ]\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(matches_dicts, f)\n",
    "\n",
    "\n",
    "def triangulatePoints(P1, P2, pts1, pts2):\n",
    "    \"\"\"\n",
    "    Triangulates the given matching points from two images using the given camera matrices.\n",
    "\n",
    "    Parameters:\n",
    "    P1 (numpy.ndarray): 3x4 camera matrix of the first image.\n",
    "    P2 (numpy.ndarray): 3x4 camera matrix of the second image.\n",
    "    pts1 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the first image.\n",
    "    pts2 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the second image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the triangulated 3D points.\n",
    "    \"\"\"\n",
    "    pts4D = OpenCV.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "    pts4D /= pts4D[3]\n",
    "    return pts4D[:3].T\n",
    "\n",
    "\n",
    "def generate_point_cloud(feature_matches_list, K_matrix):\n",
    "    \"\"\"\n",
    "    Generates a cloud of 3D points using triangulation from feature matches and camera calibration matrix.\n",
    "\n",
    "    Parameters:\n",
    "    feature_matches_list (list): List of feature matches between images.\n",
    "    K_matrix (numpy.ndarray): 3x3 camera calibration matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the cloud of 3D points.\n",
    "    \"\"\"\n",
    "    point_cloud = []\n",
    "    for match in feature_matches_list:\n",
    "        img1, img2, matches = match\n",
    "        pts1 = np.float32([kp.pt for kp in matches[0]])\n",
    "        pts2 = np.float32([kp.pt for kp in matches[1]])\n",
    "        E, _ = OpenCV.findEssentialMat(pts1, pts2, K_matrix)\n",
    "        R1, R2, t = OpenCV.decomposeEssentialMat(E)\n",
    "\n",
    "        for i in range(len(R1)):\n",
    "            P1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "            P2 = np.hstack((R1[i], t))\n",
    "            pts_3d = triangulatePoints(K_matrix.dot(P1), K_matrix.dot(P2), pts1, pts2)\n",
    "            point_cloud.append(pts_3d)\n",
    "    return np.concatenate(point_cloud, axis=0)\n",
    "\n",
    "\n",
    "def davinci_run(image_set_name):\n",
    "    print(\"Welcome ScanMate...\")\n",
    "\n",
    "    # 1. Load Images\n",
    "    images = read_images(f\"images/{image_set_name}\")\n",
    "    print(\"Images loaded successfully\")\n",
    "    gray_images = rgp_to_gray(images)\n",
    "    print(\"Gray Images created successfully\")\n",
    "    \n",
    "    # 2. Feature Extraction: SIFT\n",
    "    sift = OpenCV.SIFT_create()\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/sift-features.pkl\"):\n",
    "        print(f\"File [bak/{image_set_name}/sift-features.pkl] exists\")\n",
    "        keypoints, descriptors = load_sift_features(f\"bak/{image_set_name}/sift-features.pkl\")\n",
    "    else:\n",
    "        print(\"File [bak/{image_set_name}/sift-features.pkl] DO NOT exists\")\n",
    "        keypoints, descriptors = get_images_keypoints(gray_images, sift)\n",
    "        dump_sift_features(f\"bak/{image_set_name}/sift-features.pkl\", keypoints, descriptors)\n",
    "    print(\"Feature Extraction: SIFT DONE...\")\n",
    "\n",
    "    # 3. Image Matching\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/image-matching-centroids.pkl\"):\n",
    "        print(f\"File [bak/{image_set_name}/image-matching-centroids.pkl] exists\")\n",
    "        CLUSTER_COUNT, centroids = load_image_matching(f\"bak/{image_set_name}/image-matching-centroids.pkl\")\n",
    "    else:\n",
    "        print(f\"File [bak/{image_set_name}/image-matching-centroids.pkl] DO NOT exists\")\n",
    "        centroids, variance, CLUSTER_COUNT = match_images(descriptors)\n",
    "        dump_image_matching(f\"bak/{image_set_name}/image-matching-centroids.pkl\", CLUSTER_COUNT, centroids)\n",
    "    matches_ids = get_matches_ids(descriptors, centroids, gray_images, images)\n",
    "    print(\"Done Image Matching Step...\")\n",
    "\n",
    "    # 4. Feature Matching\n",
    "    if os.path.isfile(f\"bak/{image_set_name}/feature-matching-output.pkl\"):\n",
    "        print(f\"File [bak/{image_set_name}/feature-matching-output.pkl] exists\")\n",
    "        feature_matches = load_feature_matching(f\"bak/{image_set_name}/feature-matching-output.pkl\")\n",
    "    else:\n",
    "        print(\"File [bak/{image_set_name}/feature-matching-output.pkl] Do NOT exists\")\n",
    "        logging.info('----> Processing {image_set_name}...')\n",
    "        feature_matches = data_feature_matching(matches_ids, descriptors)\n",
    "        dump_feature_matching(f\"bak/{image_set_name}/feature-matching-output.pkl\", feature_matches)\n",
    "    \n",
    "    # 5. Camera Calibration\n",
    "    print(\"Camera Calibration starts ....\")\n",
    "    K_matrix = calibrate_camera(f\"bak/{image_set_name}/calibration.pkl\")\n",
    "    \n",
    "    # 6. Triangulation (3D reconstruction)\n",
    "    print(\"Triangulation starts ....\")\n",
    "    points_cloud = generate_point_cloud(feature_matches, K_matrix)\n",
    "    np.savetxt(\"points_cloud.txt\", points_cloud)\n",
    "    \n",
    "    # 7. generate mesh\n",
    "    print(\"Generate mesh ....\")\n",
    "    tri = Delaunay(points_cloud)\n",
    "    mesh = trimesh.Trimesh(points_cloud, tri.simplices)\n",
    "    mesh = mesh.simplify()\n",
    "\n",
    "    # 8. output .obj, .stl and .ply files\n",
    "    print(\"Generate mesh ....\")\n",
    "    mesh.export(f\"output/{image_set_name}/snow_man.obj\")\n",
    "    mesh.export(f\"output/{image_set_name}/snow_man.stl\")\n",
    "    mesh.export(f\"output/{image_set_name}/snow_man.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
