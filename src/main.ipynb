{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from typing import Final, Optional\n",
    "\n",
    "import cv2 as OpenCV\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from scipy.spatial import Delaunay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils Functions / Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_file(file_name: str, message: str):\n",
    "    import datetime\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_message = f\"[{timestamp}] {message}\"\n",
    "    with open(file_name, \"a\") as f:\n",
    "        f.write(f\"{log_message}\\n\")\n",
    "\n",
    "\n",
    "def print_size(file_name: str, obj, obj_name=\"N/A\"):\n",
    "    from pympler import asizeof\n",
    "    memory_usage = asizeof.asizeof(obj)\n",
    "    # Convert memory usage to a more readable format\n",
    "    if memory_usage < 1024:\n",
    "        memory_usage_str = f\"{memory_usage} bytes\"\n",
    "    elif memory_usage < 1024 ** 2:\n",
    "        memory_usage_str = f\"{memory_usage / 1024} KB\"\n",
    "    elif memory_usage < 1024 ** 3:\n",
    "        memory_usage_str = f\"{memory_usage / (1024 ** 2)} MB\"\n",
    "    else:\n",
    "        memory_usage_str = f\"{memory_usage / (1024 ** 3)} GB\"\n",
    "    # Print the memory usage and object name\n",
    "    log_to_file(file_name, f\"Memory usage of {obj_name}: {memory_usage_str}\")\n",
    "\n",
    "def timeit(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        image_set_name = kwargs['image_set_name']\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Started {func.__name__}...\")\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Done {func.__name__} took {end_time - start_time:,} seconds to execute.\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "class IntrinsicParametersNotFoundError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    def __init__(self, img_id, rgb_image, gray_image, keypoints, descriptors, path):\n",
    "        self.img_id: int = int(img_id)\n",
    "        self.unique_id: uuid = uuid.uuid4()\n",
    "        self.rgb_image: Image = rgb_image\n",
    "        self.gray_image: Image = gray_image\n",
    "        self.keypoints: list[OpenCV.KeyPoint] = keypoints\n",
    "        self.descriptors: np.ndarray = descriptors\n",
    "        self.path: str = path\n",
    "\n",
    "    @property\n",
    "    def length(self):\n",
    "        return f\"{len(self.keypoints)}\" if len(self.keypoints) == len(self.descriptors) else f\"{len(self.keypoints)}, {len(self.descriptors)}\"\n",
    "    \n",
    "    def draw_sift_features(self):\n",
    "        image_with_sift = OpenCV.drawKeypoints(self.rgb_image, self.keypoints, None, flags=OpenCV.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        plt.imshow(image_with_sift)\n",
    "        plt.title(\"Image with SIFT Features\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def display_rgb_image(self, title: Optional[str] = None):\n",
    "        image = self.rgb_image\n",
    "        plt.imshow(image)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def display_gray_image(self, title: Optional[str] = None):\n",
    "        image = self.gray_image\n",
    "        plt.gray()\n",
    "        plt.imshow(image)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.axes('off')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Image({self.img_id})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.unique_id == other.unique_id\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.img_id)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        state['keypoints'] = [tuple(k.pt) + (k.size, k.angle, k.response, k.octave, k.class_id) for k in self.keypoints]\n",
    "        return state\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        state['keypoints'] = [OpenCV.KeyPoint(x, y, size, angle, response, octave, class_id) for x, y, size, angle, response, octave, class_id in state['keypoints']]\n",
    "        self.__dict__ = state\n",
    "\n",
    "class FeatureMatches:\n",
    "    def __init__(self, image_one: Image, image_two: Image, matches: list[OpenCV.DMatch]):\n",
    "        self.image_one: Image = image_one\n",
    "        self.image_two: Image = image_two\n",
    "        self.matches: list[OpenCV.DMatch] = matches\n",
    "\n",
    "    def draw_matches(self, output_filename: str) -> None:\n",
    "        combined_image = OpenCV.hconcat([\n",
    "            self.image_one.rgb_image,\n",
    "            self.image_two.rgb_image\n",
    "        ])\n",
    "\n",
    "        for match in self.matches:\n",
    "            x1, y1 = self.image_one.keypoints[match.queryIdx].pt\n",
    "            x2, y2 = self.image_two.keypoints[match.trainIdx].pt\n",
    "            # Draw a line connecting the matched keypoints\n",
    "            OpenCV.line(\n",
    "                combined_image, \n",
    "                (int(x1), int(y1)), \n",
    "                (int(x2) + self.image_one.rgb_image.shape[1], int(y2)), \n",
    "                (0, 255, 0), \n",
    "                1\n",
    "            )\n",
    "\n",
    "        OpenCV.imwrite(output_filename, combined_image)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FeatureMatches({self.image_one}, {self.image_two} ---> {len(self.matches)})\"\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        state['matches'] = [\n",
    "            {'queryIdx': m.queryIdx, 'trainIdx': m.trainIdx, 'distance': m.distance} for m in self.matches\n",
    "        ]\n",
    "        return state\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        state['matches'] = [\n",
    "            OpenCV.DMatch(match['queryIdx'], match['trainIdx'], match['distance']) for match in state['matches']\n",
    "        ]\n",
    "        self.__dict__ = state\n",
    "    \n",
    "class Images:\n",
    "    def __init__(self, images: list[Image], image_set_name: str):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.images: list[Image] = images\n",
    "        self.image_set_name: str = image_set_name\n",
    "        self.feature_matches: list[FeatureMatches] = []\n",
    "        self.similar_images: dict[list[Image]] = {}\n",
    "        self.num_clusters: int = 50\n",
    "\n",
    "    def save_feature_matches(self):\n",
    "        for match in self.feature_matches:\n",
    "            match.draw_matches(f\"data/snow-man/output/feature-match/{match.image_one.img_id}_{match.image_two.img_id}.jpg\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def display_similar_images(self, key):\n",
    "        print(f\"cluster {key}\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        for value in self.similar_images[key]:\n",
    "            print(value)\n",
    "            rgb_image = OpenCV.cvtColor(OpenCV.imread(value.path), OpenCV.COLOR_BGR2RGB)\n",
    "            plt.imshow(rgb_image)\n",
    "            plt.title(value.path)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    def save_similar_images(self):\n",
    "        for cluster in self.similar_images.keys():\n",
    "            if not os.path.exists(f\"data/{self.image_set_name}/output/image-match/{cluster}\"):\n",
    "                os.makedirs(f\"data/{self.image_set_name}/output/image-match/{cluster}\")\n",
    "            for value in self.similar_images[cluster]:\n",
    "                OpenCV.imwrite(f\"data/{self.image_set_name}/output/image-match/{cluster}/{value.img_id}.jpg\", value.rgb_image)\n",
    "\n",
    "    def __getitem__(self, key: int) -> Image:\n",
    "        for image in self.images:\n",
    "            if image.img_id == key:\n",
    "                return image\n",
    "        raise KeyError(f'Image with img_id {key} not found.')\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step One: Read and Load Images\n",
    "Inputs: \n",
    "- folder_path: str\n",
    "\n",
    "Outputs:\n",
    "- images: Images\n",
    "\n",
    "Main Functions:\n",
    "1. prepare_images: read and load images from a folder into an Images object\n",
    "\n",
    "Utils Functions:\n",
    "1. dump_images: dump images to a pickle file\n",
    "2. load_images: load images from a pickle file\n",
    "\"\"\"\n",
    "\n",
    "@timeit\n",
    "def prepare_images(**kwargs) -> Images:\n",
    "    \"\"\" Read and load images \"\"\"\n",
    "    image_set_name = kwargs['image_set_name']\n",
    "    folder_path = f\"data/{image_set_name}/images\"\n",
    "    images: Images = Images([], folder_path.split(\"/\")[-2])\n",
    "    files: list[str] = filter(lambda file: \".jpg\" in file, os.listdir(folder_path))\n",
    "    for file in files:\n",
    "        image_path = f\"{folder_path}/{file}\"\n",
    "        rgb_image = OpenCV.cvtColor(OpenCV.imread(image_path), OpenCV.COLOR_BGR2RGB)\n",
    "        gray_image = OpenCV.cvtColor(rgb_image, OpenCV.COLOR_RGB2GRAY)\n",
    "        images.images.append(Image(file.split(\".\")[0], rgb_image, gray_image, [], [], image_path))\n",
    "    return images\n",
    "\n",
    "def dump_images_bak(images_file_path: str, images: Images) -> None:\n",
    "    \"\"\" Dump images to a file \"\"\"\n",
    "    with open(images_file_path, \"wb\") as file:\n",
    "        pickle.dump(images, file)\n",
    "\n",
    "def load_images_bak(images_file_path: str) -> Images:\n",
    "    \"\"\" Load images from a file \"\"\"\n",
    "    with open(images_file_path, \"rb\") as file:\n",
    "        images = pickle.load(file)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step Two: Feature Extraction\n",
    "Inputs:\n",
    "- images: Images\n",
    "- SIFT: OpenCV.SIFT\n",
    "\n",
    "Outputs:\n",
    "- image: Image\n",
    "--> image.keypoints: list[OpenCV.KeyPoint]\n",
    "--> image.descriptors: np.ndarray\n",
    "\n",
    "Main Functions:\n",
    "1. compute_keypoints_descriptors\n",
    "\"\"\"\n",
    "\n",
    "@timeit\n",
    "def compute_keypoints_descriptors(images: list[Image], SIFT: OpenCV.SIFT, **kwargs) -> None:\n",
    "    \"\"\"Compute keypoints and descriptors for each image in the list of images using SIFT algorithm.\n",
    "    Modifies each image in the list of images by adding its keypoints and descriptors as attributes.\n",
    "    \n",
    "    Args:\n",
    "    - images: List of images to compute keypoints and descriptors for.\n",
    "    - SIFT: OpenCV SIFT object used to detect and compute keypoints and descriptors.\n",
    "\n",
    "    Returns:\n",
    "    - None.\n",
    "    \"\"\"\n",
    "    image_set_name = kwargs['image_set_name']\n",
    "    for img in images.images:\n",
    "        keypoints: list[OpenCV.KeyPoint]\n",
    "        descriptors: np.ndarray\n",
    "        keypoints, descriptors = SIFT.detectAndCompute(img.gray_image, None)\n",
    "        img.keypoints = keypoints\n",
    "        img.descriptors = descriptors\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Img({img.img_id}, {img.path}) has {len(img.keypoints)} keypoints and {len(img.descriptors)} descriptors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "\n",
    "@timeit\n",
    "def image_matching(images_obj: Images, **kwargs):\n",
    "  def load_image(image_path, target_size=(224, 224)):\n",
    "    img = keras_image.load_img(image_path, target_size=target_size)\n",
    "    img = keras_image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "  \n",
    "  image_set_name = kwargs['image_set_name']\n",
    "  image_dir = f'data/{image_set_name}/images'\n",
    "  image_files = os.listdir(image_dir)\n",
    "  images = [load_image(os.path.join(image_dir, f)) for f in image_files]\n",
    "  images = np.vstack(images)\n",
    "\n",
    "  model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "  features = model.predict(images)\n",
    "\n",
    "  kmeans = KMeans(n_clusters=images_obj.num_clusters, random_state=42)\n",
    "  clusters = kmeans.fit_predict(features)\n",
    "\n",
    "  for i, cluster in enumerate(clusters):\n",
    "      if cluster not in images_obj.similar_images:\n",
    "        images_obj.similar_images[cluster] = []\n",
    "      images_obj.similar_images[cluster].append(images_obj[int(image_files[i].split(\".\")[0])])\n",
    "\n",
    "  images_obj.similar_images = {key: value for key, value in images_obj.similar_images.items() if len(value) > 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step Four: Feature Matching\n",
    "Inputs:\n",
    "- images: Images\n",
    "\n",
    "Outputs:\n",
    "- None\n",
    "\n",
    "Main Functions:\n",
    "1. data_feature_matching\n",
    "\n",
    "Utils Functions:\n",
    "1. feature_matching\n",
    "\"\"\"\n",
    "\n",
    "@timeit\n",
    "def feature_matching(\n",
    "        img_one_descriptors: np.ndarray, \n",
    "        img_two_descriptors: np.ndarray,\n",
    "        **kwargs\n",
    "    ) -> list[OpenCV.DMatch]:\n",
    "    \"\"\" Match features between two images using Brute Force Matcher\n",
    "    Args:\n",
    "        img_id_one: the index of the first image\n",
    "        img_id_two: the index of the second image\n",
    "        descriptors: a list of descriptors of the images\n",
    "    Returns:\n",
    "        A list of OpenCV.DMatch objects.\n",
    "    \"\"\"\n",
    "    matcher = OpenCV.BFMatcher()\n",
    "    return matcher.match(img_one_descriptors, img_two_descriptors)\n",
    "\n",
    "@timeit\n",
    "def apply_ransac(matches, keypoints1, keypoints2, threshold = 3.0, **kwargs):\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    _, mask = OpenCV.findHomography(src_pts, dst_pts, OpenCV.RANSAC, threshold)\n",
    "    matches_mask = mask.ravel().tolist()\n",
    "    return [m for m, keep in zip(matches, matches_mask) if keep]\n",
    "\n",
    "@timeit\n",
    "def data_feature_matching(images: Images, **kwargs) -> None:\n",
    "    \"\"\" Match features between images using Brute Force Matcher\n",
    "    Args:\n",
    "        matchesIDs: a list of lists of tuples, where each tuple contains the index of a similar image and the cosine similarity \n",
    "            between the i-th image and the similar image. The list is sorted by the cosine similarity in \n",
    "            descending order.\n",
    "        descriptors: a list of descriptors of the images\n",
    "    Returns:\n",
    "        A list of lists, where each list contains \n",
    "        the index of the first image, the index of the second image, \n",
    "        and a list of OpenCV.DMatch objects.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    image_set_name = kwargs['image_set_name']\n",
    "    for key, values in images.similar_images.items():\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Started Feature Match for cluster number {key}:\")\n",
    "        for image, matched_image in itertools.combinations(values, 2):\n",
    "            feature_matching_output = feature_matching(image.descriptors, matched_image.descriptors, **kwargs)\n",
    "            ransac_output = apply_ransac(feature_matching_output, image.keypoints, matched_image.keypoints, threshold=150, **kwargs)\n",
    "            images.feature_matches.append(FeatureMatches(image, matched_image, ransac_output))\n",
    "            log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"({image.img_id}, {matched_image.img_id}) with {len(ransac_output)} / {len(feature_matching_output)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step Five: Camera Calibration\n",
    "Inputs:\n",
    "- None.\n",
    "\n",
    "Outputs:\n",
    "- k_matrix: np.ndarray\n",
    "\n",
    "ToDo:\n",
    "1- generate K_matrix.pickle for each camera using Chess board pattern.\n",
    "\"\"\"\n",
    "\n",
    "@timeit\n",
    "def compute_k_matrix(img_path: str, **kwargs) -> np.ndarray:\n",
    "    import exifread\n",
    "    # Open the image file\n",
    "    image = open(img_path, \"rb\")\n",
    "    # Read the EXIF data\n",
    "    exif = exifread.process_file(image)\n",
    "    # Extract the intrinsic parameters\n",
    "    focal_length = exif['EXIF FocalLength'].values[0]\n",
    "    sensor_width = exif['EXIF ExifImageWidth'].values[0]\n",
    "    sensor_height = exif['EXIF ExifImageLength'].values[0]\n",
    "    principal_point_x = exif['EXIF ExifImageWidth'].values[0] / 2\n",
    "    principal_point_y = exif['EXIF ExifImageLength'].values[0] / 2\n",
    "    # distortion_coefficients = exif['EXIF MakerNote'].values[0]\n",
    "    # Calculate the scaling factor for the K-matrix\n",
    "    scaling_factor = 1.0\n",
    "    return np.array(\n",
    "        [\n",
    "            [float(focal_length), 0, principal_point_x],\n",
    "            [0, float(focal_length), principal_point_y],\n",
    "            [0, 0, scaling_factor],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step Six: Triangulation (3D Reconstruction)\n",
    "Inputs:\n",
    "- feature_matches_list: list[list[int, int, list[OpenCV.DMatch]]]\n",
    "    -> A list of lists, where each list contains \n",
    "        the index of the first image, the index of the second image, \n",
    "        and a list of OpenCV.DMatch objects.\n",
    "- K_matrix: np.ndarray\n",
    "    -> The camera matrix of the camera used to take the images.\n",
    "\n",
    "Outputs:\n",
    "- point_cloud: list[np.ndarray]; each element is a 3D point.\n",
    "\n",
    "Main Functions:\n",
    "1. generate_point_cloud\n",
    "\n",
    "Utils Functions:\n",
    "1. triangulatePoints\n",
    "\"\"\"\n",
    "@timeit\n",
    "def generate_point_cloud(images: Images, K_matrix: np.ndarray, **kwargs) -> np.ndarray:\n",
    "    point_cloud = []\n",
    "\n",
    "    for feature_match in images.feature_matches:\n",
    "        image_one = feature_match.image_one\n",
    "        image_two = feature_match.image_two\n",
    "\n",
    "        # Extract matched keypoints\n",
    "        keypoints_one = np.array([image_one.keypoints[m.queryIdx].pt for m in feature_match.matches])\n",
    "        keypoints_two = np.array([image_two.keypoints[m.trainIdx].pt for m in feature_match.matches])\n",
    "\n",
    "        # Estimate the essential matrix\n",
    "        E, mask = OpenCV.findEssentialMat(keypoints_one, keypoints_two, K_matrix, method=OpenCV.RANSAC, prob=0.999, threshold=1.0)\n",
    "        _, R, t, _ = OpenCV.recoverPose(E, keypoints_one, keypoints_two, K_matrix)\n",
    "\n",
    "        # Create projection matrices\n",
    "        P1 = K_matrix @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "        P2 = K_matrix @ np.hstack((R, t))\n",
    "\n",
    "        # Triangulate points\n",
    "        points_4D = OpenCV.triangulatePoints(P1, P2, keypoints_one.T, keypoints_two.T)\n",
    "        points_3D = (points_4D / points_4D[3])[:3]\n",
    "\n",
    "        point_cloud.append(points_3D)\n",
    "\n",
    "    # Merge all point clouds into one\n",
    "    point_cloud = np.hstack(point_cloud).T\n",
    "\n",
    "    return point_cloud\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "class Mode(enum.Enum):\n",
    "    OPTMIZED = \"optimized\"\n",
    "    DEBUG = \"debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_set_name = \"rubik-cube\"\n",
    "image_set_name = \"snow-man\"\n",
    "# image_set_name = \"test\"\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Welcome ScanMate...\")\n",
    "mode: enum = Mode.DEBUG\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Running image_set_name {image_set_name} in {mode} mode...\")\n",
    "images: Optional[Images] = None\n",
    "\n",
    "# 0. Reload the last state\n",
    "last_state: str\n",
    "if os.path.isfile(f\"data/{image_set_name}/bak/feature-matching-output.pkl\"):\n",
    "    last_state = \"Feature Matching Step\"\n",
    "elif os.path.isfile(f\"data/{image_set_name}/bak/images-matched.pkl\"):\n",
    "    last_state = \"Images Matching Step\"\n",
    "elif os.path.isfile(f\"data/{image_set_name}/bak/sift-features.pkl\"):\n",
    "    last_state = \"SIFT Features Step\"\n",
    "else:\n",
    "    last_state = \"Images Loading Step\"\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Last state for {image_set_name} is {last_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and prepare Images\n",
    "if last_state == \"Images Loading Step\":\n",
    "    if os.path.isfile(f\"data/{image_set_name}/bak/images.pkl\"):\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File [data/{image_set_name}/bak/sift-images.pkl] exists\")\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Loading images from pickle file...\")\n",
    "        images: Images = load_images_bak(f\"data/{image_set_name}/bak/images.pkl\")\n",
    "    else:\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File [data/{image_set_name}/bak/images.pkl] does not exist\")\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Loading images from images directory...\")\n",
    "        images: Images = prepare_images(image_set_name=image_set_name)\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Saving images to pickle file...\")\n",
    "        dump_images_bak(f\"data/{image_set_name}/bak/images.pkl\", images)\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Images loaded successfully\")\n",
    "    last_state = \"SIFT Features Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Extraction: SIFT\n",
    "if last_state == \"SIFT Features Step\":\n",
    "    if os.path.isfile(f\"data/{image_set_name}/bak/sift-features.pkl\"):\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File [data/{image_set_name}/bak/sift-features.pkl] exists\")\n",
    "        if images: \n",
    "            del images\n",
    "        images: Images = load_images_bak(f\"data/{image_set_name}/bak/sift-features.pkl\")\n",
    "    else:\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"File [data/{image_set_name}/bak/sift-features.pkl] DO NOT exists\")\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Extracting SIFT features...\")\n",
    "        sift = OpenCV.SIFT_create()\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images before: {sys.getrefcount(images)}\")\n",
    "        print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "        compute_keypoints_descriptors(images, sift, image_set_name=image_set_name)\n",
    "        print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images after: {sys.getrefcount(images)}\")\n",
    "        dump_images_bak(f\"data/{image_set_name}/bak/sift-features.pkl\", images)\n",
    "        # remove bak/{image_set_name}/images.pkl\n",
    "        if mode == Mode.OPTMIZED:\n",
    "            if os.path.exists(f\"data/{image_set_name}/bak/images.pkl\"):\n",
    "                os.remove(f\"data/{image_set_name}/bak/images.pkl\")\n",
    "                log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/images.pkl removed successfully.\")\n",
    "            else:\n",
    "                log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/images.pkl does not exist.\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Feature Extraction: SIFT DONE...\")\n",
    "    last_state = \"Images Matching Step\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Image Matching\n",
    "if last_state == \"Images Matching Step\":\n",
    "    if os.path.isfile(f\"data/{image_set_name}/bak/images-matched.pkl\"):\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File [data/{image_set_name}/bak/images-matched.pkl] exists\")\n",
    "        if images: \n",
    "            del images\n",
    "        images: Images = load_images_bak(f\"data/{image_set_name}/bak/images-matched.pkl\")\n",
    "    else:\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File [data/{image_set_name}/bak/images-matched.pkl] DO NOT exists\")\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Matching images...\")\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images before: {sys.getrefcount(images)}\")\n",
    "        print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "        images.num_clusters = 50\n",
    "        image_matching(images, image_set_name=image_set_name)\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"image matching done\")\n",
    "        images.save_similar_images()\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"saved image clusters\")\n",
    "        print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "        log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images after: {sys.getrefcount(images)}\")\n",
    "        dump_images_bak(f\"data/{image_set_name}/bak/images-matched.pkl\", images)\n",
    "        # remove bak/{image_set_name}/sift-features.pkl\n",
    "        if mode == Mode.OPTMIZED:\n",
    "            if os.path.exists(f\"data/{image_set_name}/bak/sift-features.pkl\"):\n",
    "                os.remove(f\"data/{image_set_name}/bak/sift-features.pkl\")\n",
    "                log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/sift-features.pkl removed successfully.\")\n",
    "            else:\n",
    "                log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/sift-features.pkl does not exist.\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Done Image Matching Step...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Feature Matching\n",
    "if os.path.isfile(f\"data/{image_set_name}/bak/feature-matching-output.pkl\"):\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File [data/{image_set_name}/bak/feature-matching-output.pkl] exists\")\n",
    "    if images: \n",
    "        del images\n",
    "    images: Images = load_images_bak(f\"data/{image_set_name}/bak/feature-matching-output.pkl\")\n",
    "else:\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"File [data/{image_set_name}/bak/feature-matching-output.pkl] Do NOT exists\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Matching features...\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images before: {sys.getrefcount(images)}\")\n",
    "    print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "    data_feature_matching(images, image_set_name=image_set_name)\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"done feature matching\")\n",
    "    images.save_feature_matches()\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"saved feature matching\")\n",
    "    print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images after: {sys.getrefcount(images)}\")\n",
    "    dump_images_bak(f\"data/{image_set_name}/bak/feature-matching-output.pkl\", images)\n",
    "    # remove bak/{image_set_name}/images-matched.pkl\n",
    "    if mode == Mode.OPTMIZED:\n",
    "        if os.path.exists(f\"data/{image_set_name}/bak/images-matched.pkl\"):\n",
    "            os.remove(f\"data/{image_set_name}/bak/images-matched.pkl\")\n",
    "            log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/images-matched.pkl removed successfully.\")\n",
    "        else:\n",
    "            log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/images-matched.pkl does not exist.\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Done Feature Matching Step...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Camera Calibration\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Camera Calibration starts ....\")\n",
    "if not os.path.isfile(f\"data/{image_set_name}/bak/K_matrix.pickle\"):\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/K_matrix.pickle does not exist\")\n",
    "    K_matrix = compute_k_matrix(images.images[0].path, image_set_name=image_set_name)\n",
    "    with open(f\"data/{image_set_name}/bak/K_matrix.pickle\", 'wb') as f:\n",
    "        pickle.dump(K_matrix, f)\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/K_matrix.pickle saved successfully\")\n",
    "else:\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/K_matrix.pickle exists\")\n",
    "    with open(f\"data/{image_set_name}/bak/K_matrix.pickle\", 'rb') as f:\n",
    "        K_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Triangulation\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Triangulation starts ....\")\n",
    "if os.path.isfile(f\"data/{image_set_name}/bak/point-cloud.pkl\"):\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/point-cloud.pkl exists\")\n",
    "    with open(f\"data/{image_set_name}/bak/point-cloud.pkl\", 'rb') as f:\n",
    "        points_cloud: np.ndarray = pickle.load(f)\n",
    "else:\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"File data/{image_set_name}/bak/point-cloud.pkl does not exist\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Triangulating...\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images before: {sys.getrefcount(images)}\")\n",
    "    print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "    points_cloud: np.ndarray = generate_point_cloud(images, K_matrix, image_set_name=image_set_name)\n",
    "    print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "    log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images after: {sys.getrefcount(images)}\")\n",
    "    # Pickle the point cloud\n",
    "    with open(f\"data/{image_set_name}/bak/point-cloud.pkl\", 'wb') as f:\n",
    "        pickle.dump(points_cloud, f)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Done Point Cloud Step...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"points_cloud.shape: {points_cloud.shape}\")\n",
    "# np.savetxt(f\"data/{image_set_name}/output/point-cloud.txt\", points_cloud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean memory before Clustring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Ref count of images before: {sys.getrefcount(images)}\")\n",
    "print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "print_size(f\"data/{image_set_name}/logs/tune.log\", points_cloud, \"points_cloud\")\n",
    "images = None\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", gc.collect())\n",
    "print_size(f\"data/{image_set_name}/logs/tune.log\", images, \"images\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Reference count<images>: {sys.getrefcount(images)}\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", gc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 3D reconstruction\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"3D reconstruction starts [points_cloud] ....\")\n",
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points_cloud[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as a .PLY file\n",
    "o3d.io.write_point_cloud(f\"data/{image_set_name}/output/point_cloud_before_clustring.ply\", pcd)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"File point_cloud_before_clustring.ply saved successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"started clustring....\")\n",
    "import hdbscan\n",
    "\n",
    "start_time = time.time()\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=10).fit(points_cloud)\n",
    "end_time = time.time()\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"time taken: {end_time - start_time:,} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/{image_set_name}/bak/hdbscan_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(hdbscan_model, f)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"File hdbscan_model.pkl saved successfully...\")\n",
    "print_size(f\"data/{image_set_name}/logs/tune.log\", hdbscan_model, \"hdbscan_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cluster labels for each point\n",
    "labels = hdbscan_model.labels_\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Labels Done...\")\n",
    "\n",
    "# Get the indices of the core points (i.e., points that are part of a dense region)\n",
    "core_indices = np.where(labels != -1)[0]\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Core Indicies Done...\")\n",
    "\n",
    "# Get the coordinates of the core points\n",
    "core_points = points_cloud[core_indices, :]\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Core Points Done...\")\n",
    "\n",
    "# Get the indices of the outlier points (i.e., points that are not part of any dense region)\n",
    "outlier_indices = np.where(labels == -1)[0]\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Outlier Indicies Done...\")\n",
    "\n",
    "# Get the coordinates of the outlier points\n",
    "outlier_points = points_cloud[outlier_indices, :]\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Outlier Points Done...\")\n",
    "\n",
    "# Log the number of clusters and the number of outlier points\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Number of clusters: {len(np.unique(labels))-1:,}\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Number of core points: {len(core_indices):,}\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Number of outlier points: {len(outlier_indices):,}\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Number of total points: {len(core_indices) + len(outlier_indices):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/{image_set_name}/bak/core_points.pkl\", 'wb') as f:\n",
    "    pickle.dump(core_points, f)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"File core_points.pkl saved successfully...\")\n",
    "print_size(f\"data/{image_set_name}/logs/tune.log\", core_points, \"core_points\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Furthur analytics on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Analysis of X, Y, Z of Points cloud\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"X<{len(points_cloud[:,0]):,}>: {points_cloud[:,0].min():,} to {points_cloud[:,0].max():,}\")\n",
    "x_counter = Counter(points_cloud[:,0])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(x_counter):,} unique X values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common X: {x_counter.most_common(1)}, Least Two Common X: {x_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", x_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Y<{len(points_cloud[:,1]):,}>: {points_cloud[:,1].min():,} to {points_cloud[:,1].max():,}\")\n",
    "y_counter = Counter(points_cloud[:,1])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(y_counter):,} unique Y values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common Y: {y_counter.most_common(1)}, Least Two Common Y: {y_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", y_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Z<{len(points_cloud[:,2]):,}>: {points_cloud[:,2].min():,} to {points_cloud[:,2].max():,}\")\n",
    "z_counter = Counter(points_cloud[:,2])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(z_counter):,} unique Z values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common Z: {z_counter.most_common(1)}, Least Two Common Y: {z_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", z_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Analysis of X, Y, Z of Core Points\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"X<{len(core_points[:,0]):,}>: {core_points[:,0].min():,} to {core_points[:,0].max():,}\")\n",
    "x_counter = Counter(core_points[:,0])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(x_counter):,} unique X values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common X: {x_counter.most_common(1)}, Least Two Common X: {x_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", x_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Y<{len(core_points[:,1]):,}>: {core_points[:,1].min():,} to {core_points[:,1].max():,}\")\n",
    "y_counter = Counter(core_points[:,1])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(y_counter):,} unique Y values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common Y: {y_counter.most_common(1)}, Least Two Common Y: {y_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", y_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Z<{len(core_points[:,2]):,}>: {core_points[:,2].min():,} to {core_points[:,2].max():,}\")\n",
    "z_counter = Counter(core_points[:,2])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(z_counter):,} unique Z values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common Z: {z_counter.most_common(1)}, Least Two Common Y: {z_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", z_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"Analysis of X, Y, Z of Outliers Points\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"X<{len(outlier_points[:,0]):,}>: {outlier_points[:,0].min():,} to {outlier_points[:,0].max():,}\")\n",
    "x_counter = Counter(outlier_points[:,0])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(x_counter):,} unique X values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common X: {x_counter.most_common(1)}, Least Two Common X: {x_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", x_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Y<{len(outlier_points[:,1]):,}>: {outlier_points[:,1].min():,} to {outlier_points[:,1].max():,}\")\n",
    "y_counter = Counter(outlier_points[:,1])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(y_counter):,} unique Y values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common Y: {y_counter.most_common(1)}, Least Two Common Y: {y_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", y_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Z<{len(outlier_points[:,2]):,}>: {outlier_points[:,2].min():,} to {outlier_points[:,2].max():,}\")\n",
    "z_counter = Counter(outlier_points[:,2])\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"We have {len(z_counter):,} unique Z values\")\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", f\"Most Common Z: {z_counter.most_common(1)}, Least Two Common Y: {z_counter.most_common()[:-3:-1]}\")\n",
    "# log_to_file(f\"data/{image_set_name}/logs/tune.log\", z_counter)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memort of pcd\n",
    "pcd = None\n",
    "\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"3D reconstruction starts [core_points] ....\")\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(core_points[:,:3])\n",
    "# Save it as a .PLY file\n",
    "o3d.io.write_point_cloud(f\"data/{image_set_name}/output/point_cloud_after_clustring.ply\", pcd)\n",
    "log_to_file(f\"data/{image_set_name}/logs/tune.log\", \"File point_cloud_after_clustring.ply saved successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# Define the path to the PLY file\n",
    "file_path = f\"data/{image_set_name}/output/point_cloud_after_clustring.ply\"\n",
    "\n",
    "# Load the point cloud from the PLY file\n",
    "point_cloud = o3d.io.read_point_cloud(file_path)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# Estimate the normals for the point cloud\n",
    "pcd.estimate_normals()\n",
    "\n",
    "# Apply the Ball-Pivoting Algorithm to create a mesh\n",
    "radii = [0.005, 0.01, 0.02, 0.04]\n",
    "bpa_mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "    pcd, o3d.utility.DoubleVector(radii)\n",
    ")\n",
    "\n",
    "# Save the mesh as an STL file\n",
    "o3d.io.write_triangle_mesh(\"snow_man_point_cloud.stl\", bpa_mesh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
