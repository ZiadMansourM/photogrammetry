{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from typing import Final, List, Tuple\n",
    "\n",
    "import cv2 as OpenCV\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from numpy.linalg import norm\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from scipy.spatial import Delaunay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "class IntrinsicParametersNotFoundError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_rbg(imagePath: str):\n",
    "    return OpenCV.cvtColor(OpenCV.imread(imagePath), OpenCV.COLOR_BGR2RGB)\n",
    "\n",
    "def rgp_to_gray(images):\n",
    "    return [OpenCV.cvtColor(image, OpenCV.COLOR_RGB2GRAY) for image in images]\n",
    "\n",
    "def read_images(folderPath):\n",
    "    files = sorted(os.listdir(folderPath))\n",
    "    return [\n",
    "        read_images_rbg(f\"{folderPath}/{file}\")\n",
    "        for file in files\n",
    "        if \".jpg\" in file\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_keypoints(GRAY_IMAGES, SIFT):\n",
    "    keypoints, descriptors = [], []\n",
    "    for i in range(len(GRAY_IMAGES)):\n",
    "        keyPoint, descriptor = SIFT.detectAndCompute(GRAY_IMAGES[i], None)\n",
    "        keypoints.append(np.array(keyPoint))\n",
    "        descriptors.append(np.array(descriptor))\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def convert_keypoints_to_tuples(\n",
    "        keypoints: List[List[OpenCV.KeyPoint]]\n",
    "        ) -> List[List[Tuple[float, float, float, float, int, int]]]:\n",
    "    \"\"\"\n",
    "    Converts a list of lists of cv2.KeyPoint objects to a list of lists of tuples, where each tuple contains the point\n",
    "    coordinates, size, angle, response, octave, and class ID of a keypoint.\n",
    "    That is done because cv2.KeyPoint objects are not serializable. And we aim to use pickle to save the keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints: A list of lists of cv2.KeyPoint objects.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists of tuples, where each tuple contains the point coordinates, size, angle, response, octave, and\n",
    "        class ID of a keypoint.\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"{keypoints[0]=}\")\n",
    "    return [\n",
    "        [\n",
    "            (kp.pt, kp.size, kp.angle, kp.response, kp.octave, kp.class_id) \n",
    "            for kp in kp_list\n",
    "        ] for kp_list in keypoints \n",
    "    ]\n",
    "\n",
    "\n",
    "def load_sift_features(path: str):\n",
    "        with open(path, 'rb') as f:\n",
    "            keypoints_tuple, descriptors = pickle.load(f)\n",
    "        keypoints = convert_tuples_to_keypoints(keypoints_tuple)\n",
    "        return keypoints, descriptors\n",
    "\n",
    "\n",
    "def dump_sift_features(path: str, keypoints, descriptors):\n",
    "    keypoints_tuples = convert_keypoints_to_tuples(keypoints)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump((keypoints_tuples, descriptors), f)\n",
    "\n",
    "\n",
    "def convert_tuples_to_keypoints(\n",
    "        keypoints_tuple: List[List[Tuple[float, float, float, float, int, int]]]\n",
    "        ) -> List[List[OpenCV.KeyPoint]]:\n",
    "    \"\"\"\n",
    "    Converts a list of lists of tuples containing point coordinates, size, angle, response, octave, and class ID of a\n",
    "    keypoint to a list of lists of cv2.KeyPoint objects.\n",
    "    That is done because cv2.KeyPoint objects are not serializable. And we aim to use pickle to save/load the keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints_tuple: A list of lists of tuples containing point coordinates, size, angle, response, octave, and\n",
    "        class ID of a keypoint.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists of cv2.KeyPoint objects.\n",
    "\n",
    "    \"\"\"\n",
    "    return [\n",
    "        [\n",
    "            OpenCV.KeyPoint(x=kp[0][0], y=kp[0][1], size=kp[1], angle=kp[2], response=kp[3], octave=kp[4], class_id=kp[5])\n",
    "            for kp in kp_array\n",
    "        ] for kp_array in keypoints_tuple\n",
    "    ]\n",
    "\n",
    "\n",
    "def match_images(descriptors):\n",
    "    all_descriptors = np.concatenate(descriptors)\n",
    "    CLUSTER_COUNT: Final = 400\n",
    "    ITER: Final = 2\n",
    "    centroids, variance = kmeans(all_descriptors, CLUSTER_COUNT, ITER)\n",
    "    return centroids, variance, CLUSTER_COUNT\n",
    "\n",
    "\n",
    "def load_image_matching(path: str):\n",
    "    return joblib.load(path)\n",
    "\n",
    "\n",
    "def dump_image_matching(path: str, CLUSTER_COUNT, centroids):\n",
    "    joblib.dump((CLUSTER_COUNT, centroids), path, compress = 3)\n",
    "\n",
    "\n",
    "def get_visual_words(descriptors, centroids):\n",
    "    visual_words = []\n",
    "    for descriptor in descriptors:\n",
    "        words, _ = vq(descriptor, centroids)\n",
    "        visual_words.append(words)\n",
    "    return visual_words\n",
    "\n",
    "\n",
    "def get_frequency_vectors(visual_words, CLUSTER_COUNT):\n",
    "    frequency_vectors = []\n",
    "    for img_words in visual_words:\n",
    "        histogram = np.zeros(CLUSTER_COUNT)\n",
    "        for word in img_words:\n",
    "            histogram[word] += 1\n",
    "        frequency_vectors.append(histogram)\n",
    "    return np.stack(frequency_vectors)\n",
    "\n",
    "\n",
    "def get_tf_idf(frequency_vectors, IMAGES_COUNT):\n",
    "    df = np.sum(frequency_vectors > 0, axis = 0)\n",
    "    idf = np.log(IMAGES_COUNT/df)\n",
    "    return frequency_vectors * idf\n",
    "\n",
    "\n",
    "def search_matches(i, top_clusters, tf_idf):\n",
    "    b = tf_idf\n",
    "    a = tf_idf[i]\n",
    "    b_subset = b[:tf_idf.shape[0]]\n",
    "    cosine_similarity = np.dot(a, b_subset.T)/(norm(a) * norm(b_subset, axis=1))\n",
    "    idx = np.argsort(-cosine_similarity)[:top_clusters]\n",
    "    return list(zip(idx, cosine_similarity[idx]))\n",
    "\n",
    "\n",
    "def get_matches_ids(descriptors, centroids, gray_images, images):\n",
    "    visual_words = get_visual_words(descriptors, centroids)\n",
    "    frequency_vectors = get_frequency_vectors(visual_words, centroids.shape[0])\n",
    "    \"\"\" tf_idf: Term Frequency-Inverse Document Frequency \"\"\"\n",
    "    tf_idf = get_tf_idf(frequency_vectors, len(gray_images))\n",
    "    return [\n",
    "        search_matches(i, 10, tf_idf) \n",
    "        for i in range(len(images))\n",
    "    ]\n",
    "\n",
    "\n",
    "def feature_matching(img_id_one, img_id_two, descriptors):\n",
    "    matcher = OpenCV.BFMatcher()\n",
    "    return matcher.match(descriptors[img_id_one], descriptors[img_id_two])\n",
    "\n",
    "\n",
    "def data_feature_matching(matchesIDs, Sdescriptors):\n",
    "    num_images = len(Sdescriptors)\n",
    "    checked = np.zeros((num_images, num_images), dtype=int)\n",
    "    feature_matches_list = []\n",
    "    for imageID in range(len(matchesIDs)):\n",
    "        logging.info(f\"---------- START Matches for: {str(imageID)}\")\n",
    "        for i, (matchedID, probability) in enumerate(matchesIDs[imageID]):\n",
    "            if ((checked[imageID][matchedID] == 0 or checked[matchedID][imageID] == 0) and imageID != matchedID and probability > 0.93):\n",
    "                start_time = time.time()\n",
    "                feature_matches_list.append([imageID, matchedID, feature_matching(imageID, matchedID, Sdescriptors)])\n",
    "                checked[imageID][matchedID], checked[matchedID][imageID] = 1, 1\n",
    "                logging.info(f\"done [{i}/{len(matchesIDs[imageID])}] in {(time.time() - start_time):.4f}: {str(imageID)} - {str(matchedID)}\")\n",
    "        # Flush the log file force write to disk\n",
    "        logging.shutdown()\n",
    "    return feature_matches_list\n",
    "\n",
    "\n",
    "def convert_matches_to_dicts(matches):\n",
    "    match_dicts = []\n",
    "    for match in matches:\n",
    "        match_dict = {'queryIdx': match.queryIdx, 'trainIdx': match.trainIdx, 'distance': match.distance}\n",
    "        match_dicts.append(match_dict)\n",
    "    return match_dicts\n",
    "\n",
    "\n",
    "def load_feature_matching(path: str):\n",
    "    with open(path, 'rb') as f:\n",
    "        feature_matches_dicts = pickle.load(f)\n",
    "    feature_matches = []\n",
    "    for match_dict in feature_matches_dicts:\n",
    "        matches = [\n",
    "            OpenCV.DMatch(\n",
    "                match['queryIdx'], \n",
    "                match['trainIdx'], \n",
    "                match['distance']\n",
    "            ) for match in match_dict[2]\n",
    "        ]\n",
    "        feature_matches.append([match_dict[0], match_dict[1], matches])\n",
    "    return feature_matches\n",
    "\n",
    "\n",
    "def dump_feature_matching(path: str, feature_matches):\n",
    "    matches_dicts = [\n",
    "        [\n",
    "            match[0],\n",
    "            match[1], \n",
    "            convert_matches_to_dicts(match[2])\n",
    "        ] for match in feature_matches\n",
    "    ]\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(matches_dicts, f)\n",
    "\n",
    "\n",
    "def triangulatePoints(P1, P2, pts1, pts2):\n",
    "    \"\"\"\n",
    "    Triangulates the given matching points from two images using the given camera matrices.\n",
    "\n",
    "    Parameters:\n",
    "    P1 (numpy.ndarray): 3x4 camera matrix of the first image.\n",
    "    P2 (numpy.ndarray): 3x4 camera matrix of the second image.\n",
    "    pts1 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the first image.\n",
    "    pts2 (numpy.ndarray): Nx2 matrix containing the coordinates of matching points in the second image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the triangulated 3D points.\n",
    "    \"\"\"\n",
    "    pts4D = OpenCV.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "    pts4D /= pts4D[3]\n",
    "    return pts4D[:3].T\n",
    "\n",
    "\n",
    "def generate_point_cloud(feature_matches_list, K_matrix):\n",
    "    \"\"\"\n",
    "    Generates a cloud of 3D points using triangulation from feature matches and camera calibration matrix.\n",
    "\n",
    "    Parameters:\n",
    "    feature_matches_list (list): List of feature matches between images.\n",
    "    K_matrix (numpy.ndarray): 3x3 camera calibration matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Nx3 matrix containing the cloud of 3D points.\n",
    "    \"\"\"\n",
    "    point_cloud = []\n",
    "    for match in feature_matches_list:\n",
    "        img1, img2, matches = match\n",
    "        pts1 = np.float32([kp.pt for kp in matches[0]])\n",
    "        pts2 = np.float32([kp.pt for kp in matches[1]])\n",
    "        E, _ = OpenCV.findEssentialMat(pts1, pts2, K_matrix)\n",
    "        R1, R2, t = OpenCV.decomposeEssentialMat(E)\n",
    "\n",
    "        for i in range(len(R1)):\n",
    "            P1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "            P2 = np.hstack((R1[i], t))\n",
    "            pts_3d = triangulatePoints(K_matrix.dot(P1), K_matrix.dot(P2), pts1, pts2)\n",
    "            point_cloud.append(pts_3d)\n",
    "    return np.concatenate(point_cloud, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Welcome ScanMate...\")\n",
    "image_set_name = \"snow-man\"\n",
    "# 1. Load Images\n",
    "images = read_images(f\"images/{image_set_name}\")\n",
    "print(\"Images loaded successfully\")\n",
    "gray_images = rgp_to_gray(images)\n",
    "print(\"Gray Images created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Extraction: SIFT\n",
    "sift = OpenCV.SIFT_create()\n",
    "if os.path.isfile(f\"bak/{image_set_name}/sift-features.pkl\"):\n",
    "    print(f\"File [bak/{image_set_name}/sift-features.pkl] exists\")\n",
    "    keypoints, descriptors = load_sift_features(f\"bak/{image_set_name}/sift-features.pkl\")\n",
    "else:\n",
    "    print(\"File [bak/{image_set_name}/sift-features.pkl] DO NOT exists\")\n",
    "    keypoints, descriptors = get_images_keypoints(gray_images, sift)\n",
    "    dump_sift_features(f\"bak/{image_set_name}/sift-features.pkl\", keypoints, descriptors)\n",
    "print(\"Feature Extraction: SIFT DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Image Matching\n",
    "if os.path.isfile(f\"bak/{image_set_name}/image-matching-centroids.pkl\"):\n",
    "    print(f\"File [bak/{image_set_name}/image-matching-centroids.pkl] exists\")\n",
    "    CLUSTER_COUNT, centroids = load_image_matching(f\"bak/{image_set_name}/image-matching-centroids.pkl\")\n",
    "else:\n",
    "    print(f\"File [bak/{image_set_name}/image-matching-centroids.pkl] DO NOT exists\")\n",
    "    centroids, variance, CLUSTER_COUNT = match_images(descriptors)\n",
    "    dump_image_matching(f\"bak/{image_set_name}/image-matching-centroids.pkl\", CLUSTER_COUNT, centroids)\n",
    "matches_ids = get_matches_ids(descriptors, centroids, gray_images, images)\n",
    "print(\"Done Image Matching Step...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Feature Matching\n",
    "if os.path.isfile(f\"bak/{image_set_name}/feature-matching-output.pkl\"):\n",
    "    print(f\"File [bak/{image_set_name}/feature-matching-output.pkl] exists\")\n",
    "    feature_matches = load_feature_matching(f\"bak/{image_set_name}/feature-matching-output.pkl\")\n",
    "else:\n",
    "    print(\"File [bak/{image_set_name}/feature-matching-output.pkl] Do NOT exists\")\n",
    "    logging.info('----> Processing {image_set_name}...')\n",
    "    feature_matches = data_feature_matching(matches_ids, descriptors)\n",
    "    dump_feature_matching(f\"bak/{image_set_name}/feature-matching-output.pkl\", feature_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Camera Calibration\n",
    "print(\"Camera Calibration starts ....\")\n",
    "if not os.path.isfile(\"bak/checker/K_matrix.pickle\"):\n",
    "    raise IntrinsicParametersNotFoundError(\"Intrinsic parameters not found\")\n",
    "with open('bak/checker/K_matrix.pickle', 'rb') as f:\n",
    "    K_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Triangulation (3D reconstruction)\n",
    "print(\"Triangulation starts ....\")\n",
    "points_cloud = generate_point_cloud(feature_matches, K_matrix)\n",
    "np.savetxt(\"points_cloud.txt\", points_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. generate mesh\n",
    "print(\"Generate mesh ....\")\n",
    "tri = Delaunay(points_cloud)\n",
    "mesh = trimesh.Trimesh(points_cloud, tri.simplices)\n",
    "mesh = mesh.simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. output .obj, .stl and .ply files\n",
    "print(\"Generate mesh ....\")\n",
    "mesh.export(f\"output/{image_set_name}/snow_man.obj\")\n",
    "mesh.export(f\"output/{image_set_name}/snow_man.stl\")\n",
    "mesh.export(f\"output/{image_set_name}/snow_man.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
