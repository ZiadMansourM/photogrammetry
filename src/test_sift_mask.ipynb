{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the regular image and mask image\n",
    "# regular_image_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\regular_images\\83.jpg'\n",
    "# mask_image_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\masked_images\\83.jpg'\n",
    "\n",
    "# regular_image = cv2.imread(regular_image_path, cv2.IMREAD_COLOR)\n",
    "# mask_image = cv2.imread(mask_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# # Create a 5x5 structuring element\n",
    "# kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# # Apply dilation to the mask image with 10 iterations\n",
    "# dilated_mask = cv2.dilate(mask_image, kernel, iterations=20)\n",
    "\n",
    "# # Save the dilated mask image\n",
    "# cv2.imwrite(r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\dilated.png', dilated_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Apply the mask to the regular image\n",
    "# masked_image = cv2.bitwise_and(regular_image, regular_image, mask=mask_image)\n",
    "# dialated_image = cv2.bitwise_and(regular_image, regular_image, mask=dilated_mask)\n",
    "# cv2.imwrite(r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\masked_image.png', masked_image)\n",
    "# cv2.imwrite(r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\dilated_image.png', dialated_image)\n",
    "\n",
    "# # Initialize the SIFT feature\n",
    "# sift = cv2.SIFT_create(contrastThreshold=0.01)\n",
    "\n",
    "# keypoints_m, descriptors_m = sift.detectAndCompute(masked_image, None)\n",
    "# result_image_masked = cv2.drawKeypoints(regular_image, keypoints_m, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# keypoints_d, descriptors_d = sift.detectAndCompute(dialated_image, None)\n",
    "# result_image_dialated = cv2.drawKeypoints(regular_image, keypoints_d, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "\n",
    "# # Save the image with the SIFT keypoints as a JPG file\n",
    "# output_image_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\output_masked.jpg'\n",
    "# cv2.imwrite(output_image_path, result_image_masked)\n",
    "\n",
    "# # Save the image with the SIFT keypoints as a JPG file\n",
    "# output_image_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\output_dialated.jpg'\n",
    "# cv2.imwrite(output_image_path, result_image_dialated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import cv2 as OpenCV\n",
    "import numpy as np\n",
    "\n",
    "def data_feature_matching_no_cross(image1, image2, descriptors_1, descriptors_2, keypoints_1, keypoints_2) -> np.ndarray:\n",
    "    matcher = OpenCV.BFMatcher(crossCheck=False)\n",
    "    feature_matching_output = matcher.match(descriptors_1, descriptors_2)\n",
    "    matched_image = cv2.drawMatches(image1, keypoints_1,\n",
    "                                    image2, keypoints_2,\n",
    "                                    feature_matching_output, None,\n",
    "                                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    return matched_image\n",
    "\n",
    "def data_feature_matching_with_cross(image1, image2, descriptors_1, descriptors_2, keypoints_1, keypoints_2) -> np.ndarray:\n",
    "    matcher = OpenCV.BFMatcher(crossCheck=True)\n",
    "    feature_matching_output = matcher.match(descriptors_1, descriptors_2)\n",
    "    matched_image = cv2.drawMatches(image1, keypoints_1,\n",
    "                                    image2, keypoints_2,\n",
    "                                    feature_matching_output, None,\n",
    "                                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    #Ransac\n",
    "    src_pts = np.float32([keypoints_1[m.queryIdx].pt for m in feature_matching_output]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints_2[m.trainIdx].pt for m in feature_matching_output]).reshape(-1, 1, 2)\n",
    "\n",
    "    _, mask = OpenCV.findHomography(src_pts, dst_pts, OpenCV.RANSAC, 150)\n",
    "    matches_mask = mask.ravel().tolist()\n",
    "    ransac_feature_matching = [m for m, keep in zip(feature_matching_output, matches_mask) if keep]\n",
    "    return cv2.drawMatches(image1, keypoints_1,\n",
    "                                    image2, keypoints_2,\n",
    "                                    ransac_feature_matching, None,\n",
    "                                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# def apply_ransac(matches, keypoints1, keypoints2, threshold = 3.0, **kwargs):\n",
    "#     src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "#     dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "#     _, mask = OpenCV.findHomography(src_pts, dst_pts, OpenCV.RANSAC, threshold)\n",
    "#     matches_mask = mask.ravel().tolist()\n",
    "#     return [m for m, keep in zip(matches, matches_mask) if keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Feature Matching (Mando and Joe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), np.uint8)\n",
    "image1_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\regular_images\\1.jpg'\n",
    "image2_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\regular_images\\2.jpg'\n",
    "masked_image_1_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\masked_images\\1.jpg'\n",
    "masked_image_2_path = r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\masked_images\\2.jpg'\n",
    "\n",
    "image1 = cv2.imread(image1_path, cv2.IMREAD_COLOR)\n",
    "image2 = cv2.imread(image2_path, cv2.IMREAD_COLOR)\n",
    "masked_image_1 = cv2.imread(masked_image_1_path, cv2.IMREAD_GRAYSCALE)\n",
    "masked_image_2 = cv2.imread(masked_image_2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sift = cv2.SIFT_create(contrastThreshold=0.01)\n",
    "dilated_mask_1 = cv2.dilate(masked_image_1, kernel, iterations=20)\n",
    "dilated_mask_2 = cv2.dilate(masked_image_2, kernel, iterations=20)\n",
    "\n",
    "dialated_image_1 = cv2.bitwise_and(image1, image1, mask=dilated_mask_1)\n",
    "dialated_image_2 = cv2.bitwise_and(image2, image2, mask=dilated_mask_2)\n",
    "\n",
    "keypoints_1, descriptors_1 = sift.detectAndCompute(dialated_image_1, None)\n",
    "result_image1_dialated = cv2.drawKeypoints(image1, keypoints_1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "keypoints_2, descriptors_2 = sift.detectAndCompute(dialated_image_2, None)\n",
    "result_image2_dialated = cv2.drawKeypoints(image2, keypoints_2, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(matcher, image1, image2, keypoints_1, keypoints_2) -> None:\n",
    "        combined_image = OpenCV.hconcat([\n",
    "            self.image_one.rgb_image,\n",
    "            self.image_two.rgb_image\n",
    "        ])\n",
    "\n",
    "        for match in matcher:\n",
    "            x1, y1 = keypoints_1[match.queryIdx].pt\n",
    "            x2, y2 = keypoints_2[match.trainIdx].pt\n",
    "            # Draw a line connecting the matched keypoints\n",
    "            OpenCV.line(\n",
    "                combined_image, \n",
    "                (int(x1), int(y1)), \n",
    "                (int(x2) + self.image_one.rgb_image.shape[1], int(y2)), \n",
    "                (0, 255, 0), \n",
    "                1\n",
    "            )\n",
    "\n",
    "        OpenCV.imwrite(output_filename, combined_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = OpenCV.BFMatcher()\n",
    "matcher.match(descriptors_1, descriptors_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage of the data_feature_matching function\n",
    "matching_image_no_cross = data_feature_matching_no_cross(result_image1_dialated, result_image2_dialated, descriptors_1, descriptors_2, keypoints_1, keypoints_2)\n",
    "matching_image_with_cross = data_feature_matching_with_cross(result_image1_dialated, result_image2_dialated, descriptors_1, descriptors_2, keypoints_1, keypoints_2)\n",
    "\n",
    "# ransac_output = apply_ransac(matcher.match(descriptors_1, descriptors_2), keypoints_1, keypoints_2, threshold=150)\n",
    "\n",
    "cv2.imwrite(r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\feature_matches_no_cross.png', matching_image_no_cross)\n",
    "cv2.imwrite(r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\ransac_feature_matches.png', matching_image_with_cross)\n",
    "# cv2.imwrite(r'C:\\Users\\yousf\\OneDrive\\Desktop\\University\\Graduation Project\\Codes\\photogrammetry\\src\\data\\hammer\\testing_outputs\\ransac_output.png', ransac_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3648\n",
      "3648\n"
     ]
    }
   ],
   "source": [
    "print(len(matching_image_no_cross))\n",
    "print(len(matching_image_with_cross))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
